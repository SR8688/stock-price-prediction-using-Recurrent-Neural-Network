{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ECE657_A3_Q2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSRhvTYr_lck",
        "outputId": "a7b56998-7fa5-4990-8359-0a3fe09ead0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvrpOBNfAm60"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arqQqq3TAUFA"
      },
      "source": [
        "# 1. load your training data\n",
        "#Loading Data set\n",
        "Stock_Data = pd.read_csv(\"/content/drive/My Drive/ECE657_a_3/data/q2_dataset.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqdEV6ArR7YF",
        "outputId": "eeeba4ae-2fa8-480d-a511-894c6b71346a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "Stock_Data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Close/Last</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>07/08/20</td>\n",
              "      <td>$381.37</td>\n",
              "      <td>29272970</td>\n",
              "      <td>376.72</td>\n",
              "      <td>381.50</td>\n",
              "      <td>376.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>07/07/20</td>\n",
              "      <td>$372.69</td>\n",
              "      <td>28106110</td>\n",
              "      <td>375.41</td>\n",
              "      <td>378.62</td>\n",
              "      <td>372.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>07/06/20</td>\n",
              "      <td>$373.85</td>\n",
              "      <td>29663910</td>\n",
              "      <td>370.00</td>\n",
              "      <td>375.78</td>\n",
              "      <td>369.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>07/02/20</td>\n",
              "      <td>$364.11</td>\n",
              "      <td>28510370</td>\n",
              "      <td>367.85</td>\n",
              "      <td>370.47</td>\n",
              "      <td>363.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>07/01/20</td>\n",
              "      <td>$364.11</td>\n",
              "      <td>27684310</td>\n",
              "      <td>365.12</td>\n",
              "      <td>367.36</td>\n",
              "      <td>363.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1254</th>\n",
              "      <td>07/15/2015</td>\n",
              "      <td>$126.82</td>\n",
              "      <td>33559770</td>\n",
              "      <td>125.72</td>\n",
              "      <td>127.15</td>\n",
              "      <td>125.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1255</th>\n",
              "      <td>07/14/2015</td>\n",
              "      <td>$125.61</td>\n",
              "      <td>31695870</td>\n",
              "      <td>126.04</td>\n",
              "      <td>126.37</td>\n",
              "      <td>125.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1256</th>\n",
              "      <td>07/13/2015</td>\n",
              "      <td>$125.66</td>\n",
              "      <td>41365600</td>\n",
              "      <td>125.03</td>\n",
              "      <td>125.76</td>\n",
              "      <td>124.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1257</th>\n",
              "      <td>07/10/15</td>\n",
              "      <td>$123.28</td>\n",
              "      <td>61292800</td>\n",
              "      <td>121.94</td>\n",
              "      <td>123.85</td>\n",
              "      <td>121.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1258</th>\n",
              "      <td>07/09/15</td>\n",
              "      <td>$120.07</td>\n",
              "      <td>78291510</td>\n",
              "      <td>123.85</td>\n",
              "      <td>124.06</td>\n",
              "      <td>119.22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1259 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date  Close/Last    Volume    Open    High     Low\n",
              "0       07/08/20     $381.37  29272970  376.72  381.50  376.36\n",
              "1       07/07/20     $372.69  28106110  375.41  378.62  372.23\n",
              "2       07/06/20     $373.85  29663910  370.00  375.78  369.87\n",
              "3       07/02/20     $364.11  28510370  367.85  370.47  363.64\n",
              "4       07/01/20     $364.11  27684310  365.12  367.36  363.91\n",
              "...          ...         ...       ...     ...     ...     ...\n",
              "1254  07/15/2015     $126.82  33559770  125.72  127.15  125.58\n",
              "1255  07/14/2015     $125.61  31695870  126.04  126.37  125.04\n",
              "1256  07/13/2015     $125.66  41365600  125.03  125.76  124.32\n",
              "1257    07/10/15     $123.28  61292800  121.94  123.85  121.21\n",
              "1258    07/09/15     $120.07  78291510  123.85  124.06  119.22\n",
              "\n",
              "[1259 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2IyK3yjVuGq",
        "outputId": "631bc04d-7c27-4359-ec9e-bb44241b8101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "store_data=np.zeros((1258,13))\n",
        "store_data.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1258, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHCotwogWB-9"
      },
      "source": [
        "'''\n",
        "\tThe dataset was created in such a way to predict the next day opening price using \n",
        "\tthe past 3 days Open, High, and Low prices and volume. So each sample contains \n",
        "\t12 features and 1 target. \n",
        "\n",
        "'''\n",
        "date_time=[]\n",
        "for i in range(len(store_data)-2):\n",
        "  # print(i)\n",
        "  #target\n",
        "  store_data[i][12]=Stock_Data.iloc[i+3][3]\n",
        "  \n",
        "  #date\n",
        "  date_time.append(Stock_Data.iloc[i+3][0])\n",
        "\n",
        "  #open -1\n",
        "  store_data[i][0]=Stock_Data.iloc[i+2][3]\n",
        "  #open -2\n",
        "  store_data[i][1]=Stock_Data.iloc[i+1][3]\n",
        "  #open -3\n",
        "  store_data[i][2]=Stock_Data.iloc[i][3]\n",
        "\n",
        "  #High -1\n",
        "  store_data[i][3]=Stock_Data.iloc[i+2][4]\n",
        "  #High -2\n",
        "  store_data[i][4]=Stock_Data.iloc[i+1][4]\n",
        "  #High -3\n",
        "  store_data[i][5]=Stock_Data.iloc[i][4]\n",
        "\n",
        "  #Low -1\n",
        "  store_data[i][6]=Stock_Data.iloc[i+2][5]\n",
        "  #Low -2\n",
        "  store_data[i][7]=Stock_Data.iloc[i+1][5]\n",
        "  #Low -3\n",
        "  store_data[i][8]=Stock_Data.iloc[i][5]\n",
        "\n",
        "  #Low -1\n",
        "  store_data[i][9]=Stock_Data.iloc[i+2][2]\n",
        "  #Low -2\n",
        "  store_data[i][10]=Stock_Data.iloc[i+1][2]\n",
        "  #Low -3\n",
        "  store_data[i][11]=Stock_Data.iloc[i][2]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEOEd3GdlsPd"
      },
      "source": [
        "date_time_df=pd.DataFrame(date_time,columns=[\"Date\"])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foR3fVVESE2x"
      },
      "source": [
        "col_names=['Open-1','Open-2','Open-3','High-1','High-2','High-3','Low-1','Low-2','Low-3','Volume-1','Volume-2','Volume-3','Target']\n",
        "df=pd.DataFrame(store_data[:-2,:],columns=col_names)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MCbyPkXTFH_",
        "outputId": "0e4ee0b9-f9c4-45a1-8aaa-acda905f1b5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open-1</th>\n",
              "      <th>Open-2</th>\n",
              "      <th>Open-3</th>\n",
              "      <th>High-1</th>\n",
              "      <th>High-2</th>\n",
              "      <th>High-3</th>\n",
              "      <th>Low-1</th>\n",
              "      <th>Low-2</th>\n",
              "      <th>Low-3</th>\n",
              "      <th>Volume-1</th>\n",
              "      <th>Volume-2</th>\n",
              "      <th>Volume-3</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>370.00</td>\n",
              "      <td>375.41</td>\n",
              "      <td>376.72</td>\n",
              "      <td>375.78</td>\n",
              "      <td>378.62</td>\n",
              "      <td>381.50</td>\n",
              "      <td>369.87</td>\n",
              "      <td>372.23</td>\n",
              "      <td>376.36</td>\n",
              "      <td>29663910.0</td>\n",
              "      <td>28106110.0</td>\n",
              "      <td>29272970.0</td>\n",
              "      <td>367.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>367.85</td>\n",
              "      <td>370.00</td>\n",
              "      <td>375.41</td>\n",
              "      <td>370.47</td>\n",
              "      <td>375.78</td>\n",
              "      <td>378.62</td>\n",
              "      <td>363.64</td>\n",
              "      <td>369.87</td>\n",
              "      <td>372.23</td>\n",
              "      <td>28510370.0</td>\n",
              "      <td>29663910.0</td>\n",
              "      <td>28106110.0</td>\n",
              "      <td>365.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>365.12</td>\n",
              "      <td>367.85</td>\n",
              "      <td>370.00</td>\n",
              "      <td>367.36</td>\n",
              "      <td>370.47</td>\n",
              "      <td>375.78</td>\n",
              "      <td>363.91</td>\n",
              "      <td>363.64</td>\n",
              "      <td>369.87</td>\n",
              "      <td>27684310.0</td>\n",
              "      <td>28510370.0</td>\n",
              "      <td>29663910.0</td>\n",
              "      <td>360.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>360.08</td>\n",
              "      <td>365.12</td>\n",
              "      <td>367.85</td>\n",
              "      <td>365.98</td>\n",
              "      <td>367.36</td>\n",
              "      <td>370.47</td>\n",
              "      <td>360.00</td>\n",
              "      <td>363.91</td>\n",
              "      <td>363.64</td>\n",
              "      <td>35055820.0</td>\n",
              "      <td>27684310.0</td>\n",
              "      <td>28510370.0</td>\n",
              "      <td>353.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>353.25</td>\n",
              "      <td>360.08</td>\n",
              "      <td>365.12</td>\n",
              "      <td>362.17</td>\n",
              "      <td>365.98</td>\n",
              "      <td>367.36</td>\n",
              "      <td>351.28</td>\n",
              "      <td>360.00</td>\n",
              "      <td>363.91</td>\n",
              "      <td>32661520.0</td>\n",
              "      <td>35055820.0</td>\n",
              "      <td>27684310.0</td>\n",
              "      <td>364.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1251</th>\n",
              "      <td>127.74</td>\n",
              "      <td>129.08</td>\n",
              "      <td>130.97</td>\n",
              "      <td>128.57</td>\n",
              "      <td>129.62</td>\n",
              "      <td>132.97</td>\n",
              "      <td>127.35</td>\n",
              "      <td>128.31</td>\n",
              "      <td>130.70</td>\n",
              "      <td>35987630.0</td>\n",
              "      <td>45970470.0</td>\n",
              "      <td>55204920.0</td>\n",
              "      <td>125.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1252</th>\n",
              "      <td>125.72</td>\n",
              "      <td>127.74</td>\n",
              "      <td>129.08</td>\n",
              "      <td>127.15</td>\n",
              "      <td>128.57</td>\n",
              "      <td>129.62</td>\n",
              "      <td>125.58</td>\n",
              "      <td>127.35</td>\n",
              "      <td>128.31</td>\n",
              "      <td>33559770.0</td>\n",
              "      <td>35987630.0</td>\n",
              "      <td>45970470.0</td>\n",
              "      <td>126.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1253</th>\n",
              "      <td>126.04</td>\n",
              "      <td>125.72</td>\n",
              "      <td>127.74</td>\n",
              "      <td>126.37</td>\n",
              "      <td>127.15</td>\n",
              "      <td>128.57</td>\n",
              "      <td>125.04</td>\n",
              "      <td>125.58</td>\n",
              "      <td>127.35</td>\n",
              "      <td>31695870.0</td>\n",
              "      <td>33559770.0</td>\n",
              "      <td>35987630.0</td>\n",
              "      <td>125.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1254</th>\n",
              "      <td>125.03</td>\n",
              "      <td>126.04</td>\n",
              "      <td>125.72</td>\n",
              "      <td>125.76</td>\n",
              "      <td>126.37</td>\n",
              "      <td>127.15</td>\n",
              "      <td>124.32</td>\n",
              "      <td>125.04</td>\n",
              "      <td>125.58</td>\n",
              "      <td>41365600.0</td>\n",
              "      <td>31695870.0</td>\n",
              "      <td>33559770.0</td>\n",
              "      <td>121.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1255</th>\n",
              "      <td>121.94</td>\n",
              "      <td>125.03</td>\n",
              "      <td>126.04</td>\n",
              "      <td>123.85</td>\n",
              "      <td>125.76</td>\n",
              "      <td>126.37</td>\n",
              "      <td>121.21</td>\n",
              "      <td>124.32</td>\n",
              "      <td>125.04</td>\n",
              "      <td>61292800.0</td>\n",
              "      <td>41365600.0</td>\n",
              "      <td>31695870.0</td>\n",
              "      <td>123.85</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1256 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Open-1  Open-2  Open-3  ...    Volume-2    Volume-3  Target\n",
              "0     370.00  375.41  376.72  ...  28106110.0  29272970.0  367.85\n",
              "1     367.85  370.00  375.41  ...  29663910.0  28106110.0  365.12\n",
              "2     365.12  367.85  370.00  ...  28510370.0  29663910.0  360.08\n",
              "3     360.08  365.12  367.85  ...  27684310.0  28510370.0  353.25\n",
              "4     353.25  360.08  365.12  ...  35055820.0  27684310.0  364.41\n",
              "...      ...     ...     ...  ...         ...         ...     ...\n",
              "1251  127.74  129.08  130.97  ...  45970470.0  55204920.0  125.72\n",
              "1252  125.72  127.74  129.08  ...  35987630.0  45970470.0  126.04\n",
              "1253  126.04  125.72  127.74  ...  33559770.0  35987630.0  125.03\n",
              "1254  125.03  126.04  125.72  ...  31695870.0  33559770.0  121.94\n",
              "1255  121.94  125.03  126.04  ...  41365600.0  31695870.0  123.85\n",
              "\n",
              "[1256 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSISOjA2N9qA"
      },
      "source": [
        "data=df.drop(['Target'],axis=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVoAA9eTO0ro",
        "outputId": "170e31a3-1f13-426d-9e9b-84af6c293343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "data"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open-1</th>\n",
              "      <th>Open-2</th>\n",
              "      <th>Open-3</th>\n",
              "      <th>High-1</th>\n",
              "      <th>High-2</th>\n",
              "      <th>High-3</th>\n",
              "      <th>Low-1</th>\n",
              "      <th>Low-2</th>\n",
              "      <th>Low-3</th>\n",
              "      <th>Volume-1</th>\n",
              "      <th>Volume-2</th>\n",
              "      <th>Volume-3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>370.00</td>\n",
              "      <td>375.41</td>\n",
              "      <td>376.72</td>\n",
              "      <td>375.78</td>\n",
              "      <td>378.62</td>\n",
              "      <td>381.50</td>\n",
              "      <td>369.87</td>\n",
              "      <td>372.23</td>\n",
              "      <td>376.36</td>\n",
              "      <td>29663910.0</td>\n",
              "      <td>28106110.0</td>\n",
              "      <td>29272970.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>367.85</td>\n",
              "      <td>370.00</td>\n",
              "      <td>375.41</td>\n",
              "      <td>370.47</td>\n",
              "      <td>375.78</td>\n",
              "      <td>378.62</td>\n",
              "      <td>363.64</td>\n",
              "      <td>369.87</td>\n",
              "      <td>372.23</td>\n",
              "      <td>28510370.0</td>\n",
              "      <td>29663910.0</td>\n",
              "      <td>28106110.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>365.12</td>\n",
              "      <td>367.85</td>\n",
              "      <td>370.00</td>\n",
              "      <td>367.36</td>\n",
              "      <td>370.47</td>\n",
              "      <td>375.78</td>\n",
              "      <td>363.91</td>\n",
              "      <td>363.64</td>\n",
              "      <td>369.87</td>\n",
              "      <td>27684310.0</td>\n",
              "      <td>28510370.0</td>\n",
              "      <td>29663910.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>360.08</td>\n",
              "      <td>365.12</td>\n",
              "      <td>367.85</td>\n",
              "      <td>365.98</td>\n",
              "      <td>367.36</td>\n",
              "      <td>370.47</td>\n",
              "      <td>360.00</td>\n",
              "      <td>363.91</td>\n",
              "      <td>363.64</td>\n",
              "      <td>35055820.0</td>\n",
              "      <td>27684310.0</td>\n",
              "      <td>28510370.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>353.25</td>\n",
              "      <td>360.08</td>\n",
              "      <td>365.12</td>\n",
              "      <td>362.17</td>\n",
              "      <td>365.98</td>\n",
              "      <td>367.36</td>\n",
              "      <td>351.28</td>\n",
              "      <td>360.00</td>\n",
              "      <td>363.91</td>\n",
              "      <td>32661520.0</td>\n",
              "      <td>35055820.0</td>\n",
              "      <td>27684310.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1251</th>\n",
              "      <td>127.74</td>\n",
              "      <td>129.08</td>\n",
              "      <td>130.97</td>\n",
              "      <td>128.57</td>\n",
              "      <td>129.62</td>\n",
              "      <td>132.97</td>\n",
              "      <td>127.35</td>\n",
              "      <td>128.31</td>\n",
              "      <td>130.70</td>\n",
              "      <td>35987630.0</td>\n",
              "      <td>45970470.0</td>\n",
              "      <td>55204920.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1252</th>\n",
              "      <td>125.72</td>\n",
              "      <td>127.74</td>\n",
              "      <td>129.08</td>\n",
              "      <td>127.15</td>\n",
              "      <td>128.57</td>\n",
              "      <td>129.62</td>\n",
              "      <td>125.58</td>\n",
              "      <td>127.35</td>\n",
              "      <td>128.31</td>\n",
              "      <td>33559770.0</td>\n",
              "      <td>35987630.0</td>\n",
              "      <td>45970470.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1253</th>\n",
              "      <td>126.04</td>\n",
              "      <td>125.72</td>\n",
              "      <td>127.74</td>\n",
              "      <td>126.37</td>\n",
              "      <td>127.15</td>\n",
              "      <td>128.57</td>\n",
              "      <td>125.04</td>\n",
              "      <td>125.58</td>\n",
              "      <td>127.35</td>\n",
              "      <td>31695870.0</td>\n",
              "      <td>33559770.0</td>\n",
              "      <td>35987630.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1254</th>\n",
              "      <td>125.03</td>\n",
              "      <td>126.04</td>\n",
              "      <td>125.72</td>\n",
              "      <td>125.76</td>\n",
              "      <td>126.37</td>\n",
              "      <td>127.15</td>\n",
              "      <td>124.32</td>\n",
              "      <td>125.04</td>\n",
              "      <td>125.58</td>\n",
              "      <td>41365600.0</td>\n",
              "      <td>31695870.0</td>\n",
              "      <td>33559770.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1255</th>\n",
              "      <td>121.94</td>\n",
              "      <td>125.03</td>\n",
              "      <td>126.04</td>\n",
              "      <td>123.85</td>\n",
              "      <td>125.76</td>\n",
              "      <td>126.37</td>\n",
              "      <td>121.21</td>\n",
              "      <td>124.32</td>\n",
              "      <td>125.04</td>\n",
              "      <td>61292800.0</td>\n",
              "      <td>41365600.0</td>\n",
              "      <td>31695870.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1256 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Open-1  Open-2  Open-3  ...    Volume-1    Volume-2    Volume-3\n",
              "0     370.00  375.41  376.72  ...  29663910.0  28106110.0  29272970.0\n",
              "1     367.85  370.00  375.41  ...  28510370.0  29663910.0  28106110.0\n",
              "2     365.12  367.85  370.00  ...  27684310.0  28510370.0  29663910.0\n",
              "3     360.08  365.12  367.85  ...  35055820.0  27684310.0  28510370.0\n",
              "4     353.25  360.08  365.12  ...  32661520.0  35055820.0  27684310.0\n",
              "...      ...     ...     ...  ...         ...         ...         ...\n",
              "1251  127.74  129.08  130.97  ...  35987630.0  45970470.0  55204920.0\n",
              "1252  125.72  127.74  129.08  ...  33559770.0  35987630.0  45970470.0\n",
              "1253  126.04  125.72  127.74  ...  31695870.0  33559770.0  35987630.0\n",
              "1254  125.03  126.04  125.72  ...  41365600.0  31695870.0  33559770.0\n",
              "1255  121.94  125.03  126.04  ...  61292800.0  41365600.0  31695870.0\n",
              "\n",
              "[1256 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQFswvfTm3KV"
      },
      "source": [
        "frames = [data,date_time_df]\n",
        "data_date_df = pd.concat(frames,axis=1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjIXu7emn2Lj",
        "outputId": "7c77fae4-a50b-4d9e-9ac7-26ba9775131f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "data_date_df"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open-1</th>\n",
              "      <th>Open-2</th>\n",
              "      <th>Open-3</th>\n",
              "      <th>High-1</th>\n",
              "      <th>High-2</th>\n",
              "      <th>High-3</th>\n",
              "      <th>Low-1</th>\n",
              "      <th>Low-2</th>\n",
              "      <th>Low-3</th>\n",
              "      <th>Volume-1</th>\n",
              "      <th>Volume-2</th>\n",
              "      <th>Volume-3</th>\n",
              "      <th>Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>370.00</td>\n",
              "      <td>375.41</td>\n",
              "      <td>376.72</td>\n",
              "      <td>375.78</td>\n",
              "      <td>378.62</td>\n",
              "      <td>381.50</td>\n",
              "      <td>369.87</td>\n",
              "      <td>372.23</td>\n",
              "      <td>376.36</td>\n",
              "      <td>29663910.0</td>\n",
              "      <td>28106110.0</td>\n",
              "      <td>29272970.0</td>\n",
              "      <td>07/02/20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>367.85</td>\n",
              "      <td>370.00</td>\n",
              "      <td>375.41</td>\n",
              "      <td>370.47</td>\n",
              "      <td>375.78</td>\n",
              "      <td>378.62</td>\n",
              "      <td>363.64</td>\n",
              "      <td>369.87</td>\n",
              "      <td>372.23</td>\n",
              "      <td>28510370.0</td>\n",
              "      <td>29663910.0</td>\n",
              "      <td>28106110.0</td>\n",
              "      <td>07/01/20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>365.12</td>\n",
              "      <td>367.85</td>\n",
              "      <td>370.00</td>\n",
              "      <td>367.36</td>\n",
              "      <td>370.47</td>\n",
              "      <td>375.78</td>\n",
              "      <td>363.91</td>\n",
              "      <td>363.64</td>\n",
              "      <td>369.87</td>\n",
              "      <td>27684310.0</td>\n",
              "      <td>28510370.0</td>\n",
              "      <td>29663910.0</td>\n",
              "      <td>06/30/2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>360.08</td>\n",
              "      <td>365.12</td>\n",
              "      <td>367.85</td>\n",
              "      <td>365.98</td>\n",
              "      <td>367.36</td>\n",
              "      <td>370.47</td>\n",
              "      <td>360.00</td>\n",
              "      <td>363.91</td>\n",
              "      <td>363.64</td>\n",
              "      <td>35055820.0</td>\n",
              "      <td>27684310.0</td>\n",
              "      <td>28510370.0</td>\n",
              "      <td>06/29/2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>353.25</td>\n",
              "      <td>360.08</td>\n",
              "      <td>365.12</td>\n",
              "      <td>362.17</td>\n",
              "      <td>365.98</td>\n",
              "      <td>367.36</td>\n",
              "      <td>351.28</td>\n",
              "      <td>360.00</td>\n",
              "      <td>363.91</td>\n",
              "      <td>32661520.0</td>\n",
              "      <td>35055820.0</td>\n",
              "      <td>27684310.0</td>\n",
              "      <td>06/26/2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1251</th>\n",
              "      <td>127.74</td>\n",
              "      <td>129.08</td>\n",
              "      <td>130.97</td>\n",
              "      <td>128.57</td>\n",
              "      <td>129.62</td>\n",
              "      <td>132.97</td>\n",
              "      <td>127.35</td>\n",
              "      <td>128.31</td>\n",
              "      <td>130.70</td>\n",
              "      <td>35987630.0</td>\n",
              "      <td>45970470.0</td>\n",
              "      <td>55204920.0</td>\n",
              "      <td>07/15/2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1252</th>\n",
              "      <td>125.72</td>\n",
              "      <td>127.74</td>\n",
              "      <td>129.08</td>\n",
              "      <td>127.15</td>\n",
              "      <td>128.57</td>\n",
              "      <td>129.62</td>\n",
              "      <td>125.58</td>\n",
              "      <td>127.35</td>\n",
              "      <td>128.31</td>\n",
              "      <td>33559770.0</td>\n",
              "      <td>35987630.0</td>\n",
              "      <td>45970470.0</td>\n",
              "      <td>07/14/2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1253</th>\n",
              "      <td>126.04</td>\n",
              "      <td>125.72</td>\n",
              "      <td>127.74</td>\n",
              "      <td>126.37</td>\n",
              "      <td>127.15</td>\n",
              "      <td>128.57</td>\n",
              "      <td>125.04</td>\n",
              "      <td>125.58</td>\n",
              "      <td>127.35</td>\n",
              "      <td>31695870.0</td>\n",
              "      <td>33559770.0</td>\n",
              "      <td>35987630.0</td>\n",
              "      <td>07/13/2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1254</th>\n",
              "      <td>125.03</td>\n",
              "      <td>126.04</td>\n",
              "      <td>125.72</td>\n",
              "      <td>125.76</td>\n",
              "      <td>126.37</td>\n",
              "      <td>127.15</td>\n",
              "      <td>124.32</td>\n",
              "      <td>125.04</td>\n",
              "      <td>125.58</td>\n",
              "      <td>41365600.0</td>\n",
              "      <td>31695870.0</td>\n",
              "      <td>33559770.0</td>\n",
              "      <td>07/10/15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1255</th>\n",
              "      <td>121.94</td>\n",
              "      <td>125.03</td>\n",
              "      <td>126.04</td>\n",
              "      <td>123.85</td>\n",
              "      <td>125.76</td>\n",
              "      <td>126.37</td>\n",
              "      <td>121.21</td>\n",
              "      <td>124.32</td>\n",
              "      <td>125.04</td>\n",
              "      <td>61292800.0</td>\n",
              "      <td>41365600.0</td>\n",
              "      <td>31695870.0</td>\n",
              "      <td>07/09/15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1256 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Open-1  Open-2  Open-3  ...    Volume-2    Volume-3        Date\n",
              "0     370.00  375.41  376.72  ...  28106110.0  29272970.0    07/02/20\n",
              "1     367.85  370.00  375.41  ...  29663910.0  28106110.0    07/01/20\n",
              "2     365.12  367.85  370.00  ...  28510370.0  29663910.0  06/30/2020\n",
              "3     360.08  365.12  367.85  ...  27684310.0  28510370.0  06/29/2020\n",
              "4     353.25  360.08  365.12  ...  35055820.0  27684310.0  06/26/2020\n",
              "...      ...     ...     ...  ...         ...         ...         ...\n",
              "1251  127.74  129.08  130.97  ...  45970470.0  55204920.0  07/15/2015\n",
              "1252  125.72  127.74  129.08  ...  35987630.0  45970470.0  07/14/2015\n",
              "1253  126.04  125.72  127.74  ...  33559770.0  35987630.0  07/13/2015\n",
              "1254  125.03  126.04  125.72  ...  31695870.0  33559770.0    07/10/15\n",
              "1255  121.94  125.03  126.04  ...  41365600.0  31695870.0    07/09/15\n",
              "\n",
              "[1256 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fyYlX6iUJJh"
      },
      "source": [
        "#the dataset was randomized to create ‘train_data_RNN.csv’ and ‘test_data_RNN.csv.\n",
        "ran = 42\n",
        "X_train_date, X_test_date, y_train, y_test = train_test_split(data_date_df, df['Target'], test_size=0.3, random_state = ran) "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpNEvu08n_yq",
        "outputId": "966f68a8-fa55-4d94-9ba3-3323e02b61dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "X_train=X_train_date.drop(['Date'],axis=1)\n",
        "X_train"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open-1</th>\n",
              "      <th>Open-2</th>\n",
              "      <th>Open-3</th>\n",
              "      <th>High-1</th>\n",
              "      <th>High-2</th>\n",
              "      <th>High-3</th>\n",
              "      <th>Low-1</th>\n",
              "      <th>Low-2</th>\n",
              "      <th>Low-3</th>\n",
              "      <th>Volume-1</th>\n",
              "      <th>Volume-2</th>\n",
              "      <th>Volume-3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1149</th>\n",
              "      <td>117.64</td>\n",
              "      <td>116.04</td>\n",
              "      <td>115.19</td>\n",
              "      <td>117.69</td>\n",
              "      <td>116.94</td>\n",
              "      <td>115.39</td>\n",
              "      <td>115.08</td>\n",
              "      <td>115.51</td>\n",
              "      <td>112.85</td>\n",
              "      <td>46301930.0</td>\n",
              "      <td>29158640.0</td>\n",
              "      <td>46810020.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905</th>\n",
              "      <td>111.43</td>\n",
              "      <td>110.78</td>\n",
              "      <td>111.60</td>\n",
              "      <td>112.47</td>\n",
              "      <td>112.03</td>\n",
              "      <td>112.20</td>\n",
              "      <td>111.39</td>\n",
              "      <td>110.07</td>\n",
              "      <td>110.27</td>\n",
              "      <td>27054320.0</td>\n",
              "      <td>28507780.0</td>\n",
              "      <td>36151450.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>724</th>\n",
              "      <td>160.52</td>\n",
              "      <td>157.86</td>\n",
              "      <td>157.50</td>\n",
              "      <td>160.71</td>\n",
              "      <td>159.50</td>\n",
              "      <td>157.89</td>\n",
              "      <td>157.84</td>\n",
              "      <td>156.72</td>\n",
              "      <td>155.11</td>\n",
              "      <td>27377960.0</td>\n",
              "      <td>27391950.0</td>\n",
              "      <td>26330070.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552</th>\n",
              "      <td>162.62</td>\n",
              "      <td>164.12</td>\n",
              "      <td>164.00</td>\n",
              "      <td>165.42</td>\n",
              "      <td>165.73</td>\n",
              "      <td>164.33</td>\n",
              "      <td>162.41</td>\n",
              "      <td>163.37</td>\n",
              "      <td>160.63</td>\n",
              "      <td>28331540.0</td>\n",
              "      <td>27850370.0</td>\n",
              "      <td>35617230.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>255.60</td>\n",
              "      <td>246.50</td>\n",
              "      <td>240.34</td>\n",
              "      <td>262.49</td>\n",
              "      <td>248.72</td>\n",
              "      <td>245.15</td>\n",
              "      <td>252.00</td>\n",
              "      <td>239.13</td>\n",
              "      <td>236.90</td>\n",
              "      <td>49250500.0</td>\n",
              "      <td>44054640.0</td>\n",
              "      <td>41483490.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1044</th>\n",
              "      <td>93.48</td>\n",
              "      <td>92.72</td>\n",
              "      <td>90.00</td>\n",
              "      <td>93.57</td>\n",
              "      <td>92.78</td>\n",
              "      <td>91.67</td>\n",
              "      <td>92.46</td>\n",
              "      <td>89.47</td>\n",
              "      <td>90.00</td>\n",
              "      <td>28641180.0</td>\n",
              "      <td>76183460.0</td>\n",
              "      <td>44223040.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1095</th>\n",
              "      <td>96.86</td>\n",
              "      <td>97.65</td>\n",
              "      <td>100.51</td>\n",
              "      <td>98.23</td>\n",
              "      <td>100.77</td>\n",
              "      <td>100.89</td>\n",
              "      <td>96.65</td>\n",
              "      <td>97.42</td>\n",
              "      <td>99.64</td>\n",
              "      <td>35131460.0</td>\n",
              "      <td>50303500.0</td>\n",
              "      <td>33136130.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>98.68</td>\n",
              "      <td>98.55</td>\n",
              "      <td>98.97</td>\n",
              "      <td>100.13</td>\n",
              "      <td>99.11</td>\n",
              "      <td>99.06</td>\n",
              "      <td>96.43</td>\n",
              "      <td>96.76</td>\n",
              "      <td>97.34</td>\n",
              "      <td>80742460.0</td>\n",
              "      <td>70722000.0</td>\n",
              "      <td>49687870.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>127.98</td>\n",
              "      <td>128.31</td>\n",
              "      <td>129.13</td>\n",
              "      <td>129.39</td>\n",
              "      <td>129.19</td>\n",
              "      <td>130.50</td>\n",
              "      <td>127.78</td>\n",
              "      <td>128.16</td>\n",
              "      <td>128.90</td>\n",
              "      <td>33671250.0</td>\n",
              "      <td>24460160.0</td>\n",
              "      <td>26784530.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1126</th>\n",
              "      <td>100.32</td>\n",
              "      <td>97.96</td>\n",
              "      <td>96.20</td>\n",
              "      <td>101.19</td>\n",
              "      <td>100.48</td>\n",
              "      <td>97.71</td>\n",
              "      <td>97.30</td>\n",
              "      <td>95.74</td>\n",
              "      <td>95.36</td>\n",
              "      <td>62285770.0</td>\n",
              "      <td>63000140.0</td>\n",
              "      <td>79356010.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>879 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Open-1  Open-2  Open-3  ...    Volume-1    Volume-2    Volume-3\n",
              "1149  117.64  116.04  115.19  ...  46301930.0  29158640.0  46810020.0\n",
              "905   111.43  110.78  111.60  ...  27054320.0  28507780.0  36151450.0\n",
              "724   160.52  157.86  157.50  ...  27377960.0  27391950.0  26330070.0\n",
              "552   162.62  164.12  164.00  ...  28331540.0  27850370.0  35617230.0\n",
              "66    255.60  246.50  240.34  ...  49250500.0  44054640.0  41483490.0\n",
              "...      ...     ...     ...  ...         ...         ...         ...\n",
              "1044   93.48   92.72   90.00  ...  28641180.0  76183460.0  44223040.0\n",
              "1095   96.86   97.65  100.51  ...  35131460.0  50303500.0  33136130.0\n",
              "1130   98.68   98.55   98.97  ...  80742460.0  70722000.0  49687870.0\n",
              "860   127.98  128.31  129.13  ...  33671250.0  24460160.0  26784530.0\n",
              "1126  100.32   97.96   96.20  ...  62285770.0  63000140.0  79356010.0\n",
              "\n",
              "[879 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWe2p3GwO4mL"
      },
      "source": [
        "train_data=pd.concat([X_train,y_train],axis=1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ5W46N0PNG5",
        "outputId": "493129cf-a29f-4cec-a439-36d2ea06f502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "train_data"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open-1</th>\n",
              "      <th>Open-2</th>\n",
              "      <th>Open-3</th>\n",
              "      <th>High-1</th>\n",
              "      <th>High-2</th>\n",
              "      <th>High-3</th>\n",
              "      <th>Low-1</th>\n",
              "      <th>Low-2</th>\n",
              "      <th>Low-3</th>\n",
              "      <th>Volume-1</th>\n",
              "      <th>Volume-2</th>\n",
              "      <th>Volume-3</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1149</th>\n",
              "      <td>117.64</td>\n",
              "      <td>116.04</td>\n",
              "      <td>115.19</td>\n",
              "      <td>117.69</td>\n",
              "      <td>116.94</td>\n",
              "      <td>115.39</td>\n",
              "      <td>115.08</td>\n",
              "      <td>115.51</td>\n",
              "      <td>112.85</td>\n",
              "      <td>46301930.0</td>\n",
              "      <td>29158640.0</td>\n",
              "      <td>46810020.0</td>\n",
              "      <td>117.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905</th>\n",
              "      <td>111.43</td>\n",
              "      <td>110.78</td>\n",
              "      <td>111.60</td>\n",
              "      <td>112.47</td>\n",
              "      <td>112.03</td>\n",
              "      <td>112.20</td>\n",
              "      <td>111.39</td>\n",
              "      <td>110.07</td>\n",
              "      <td>110.27</td>\n",
              "      <td>27054320.0</td>\n",
              "      <td>28507780.0</td>\n",
              "      <td>36151450.0</td>\n",
              "      <td>111.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>724</th>\n",
              "      <td>160.52</td>\n",
              "      <td>157.86</td>\n",
              "      <td>157.50</td>\n",
              "      <td>160.71</td>\n",
              "      <td>159.50</td>\n",
              "      <td>157.89</td>\n",
              "      <td>157.84</td>\n",
              "      <td>156.72</td>\n",
              "      <td>155.11</td>\n",
              "      <td>27377960.0</td>\n",
              "      <td>27391950.0</td>\n",
              "      <td>26330070.0</td>\n",
              "      <td>161.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552</th>\n",
              "      <td>162.62</td>\n",
              "      <td>164.12</td>\n",
              "      <td>164.00</td>\n",
              "      <td>165.42</td>\n",
              "      <td>165.73</td>\n",
              "      <td>164.33</td>\n",
              "      <td>162.41</td>\n",
              "      <td>163.37</td>\n",
              "      <td>160.63</td>\n",
              "      <td>28331540.0</td>\n",
              "      <td>27850370.0</td>\n",
              "      <td>35617230.0</td>\n",
              "      <td>165.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>255.60</td>\n",
              "      <td>246.50</td>\n",
              "      <td>240.34</td>\n",
              "      <td>262.49</td>\n",
              "      <td>248.72</td>\n",
              "      <td>245.15</td>\n",
              "      <td>252.00</td>\n",
              "      <td>239.13</td>\n",
              "      <td>236.90</td>\n",
              "      <td>49250500.0</td>\n",
              "      <td>44054640.0</td>\n",
              "      <td>41483490.0</td>\n",
              "      <td>250.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1044</th>\n",
              "      <td>93.48</td>\n",
              "      <td>92.72</td>\n",
              "      <td>90.00</td>\n",
              "      <td>93.57</td>\n",
              "      <td>92.78</td>\n",
              "      <td>91.67</td>\n",
              "      <td>92.46</td>\n",
              "      <td>89.47</td>\n",
              "      <td>90.00</td>\n",
              "      <td>28641180.0</td>\n",
              "      <td>76183460.0</td>\n",
              "      <td>44223040.0</td>\n",
              "      <td>93.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1095</th>\n",
              "      <td>96.86</td>\n",
              "      <td>97.65</td>\n",
              "      <td>100.51</td>\n",
              "      <td>98.23</td>\n",
              "      <td>100.77</td>\n",
              "      <td>100.89</td>\n",
              "      <td>96.65</td>\n",
              "      <td>97.42</td>\n",
              "      <td>99.64</td>\n",
              "      <td>35131460.0</td>\n",
              "      <td>50303500.0</td>\n",
              "      <td>33136130.0</td>\n",
              "      <td>97.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>98.68</td>\n",
              "      <td>98.55</td>\n",
              "      <td>98.97</td>\n",
              "      <td>100.13</td>\n",
              "      <td>99.11</td>\n",
              "      <td>99.06</td>\n",
              "      <td>96.43</td>\n",
              "      <td>96.76</td>\n",
              "      <td>97.34</td>\n",
              "      <td>80742460.0</td>\n",
              "      <td>70722000.0</td>\n",
              "      <td>49687870.0</td>\n",
              "      <td>100.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>127.98</td>\n",
              "      <td>128.31</td>\n",
              "      <td>129.13</td>\n",
              "      <td>129.39</td>\n",
              "      <td>129.19</td>\n",
              "      <td>130.50</td>\n",
              "      <td>127.78</td>\n",
              "      <td>128.16</td>\n",
              "      <td>128.90</td>\n",
              "      <td>33671250.0</td>\n",
              "      <td>24460160.0</td>\n",
              "      <td>26784530.0</td>\n",
              "      <td>127.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1126</th>\n",
              "      <td>100.32</td>\n",
              "      <td>97.96</td>\n",
              "      <td>96.20</td>\n",
              "      <td>101.19</td>\n",
              "      <td>100.48</td>\n",
              "      <td>97.71</td>\n",
              "      <td>97.30</td>\n",
              "      <td>95.74</td>\n",
              "      <td>95.36</td>\n",
              "      <td>62285770.0</td>\n",
              "      <td>63000140.0</td>\n",
              "      <td>79356010.0</td>\n",
              "      <td>100.55</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>879 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Open-1  Open-2  Open-3  ...    Volume-2    Volume-3  Target\n",
              "1149  117.64  116.04  115.19  ...  29158640.0  46810020.0  117.52\n",
              "905   111.43  110.78  111.60  ...  28507780.0  36151450.0  111.13\n",
              "724   160.52  157.86  157.50  ...  27391950.0  26330070.0  161.94\n",
              "552   162.62  164.12  164.00  ...  27850370.0  35617230.0  165.67\n",
              "66    255.60  246.50  240.34  ...  44054640.0  41483490.0  250.74\n",
              "...      ...     ...     ...  ...         ...         ...     ...\n",
              "1044   93.48   92.72   90.00  ...  76183460.0  44223040.0   93.33\n",
              "1095   96.86   97.65  100.51  ...  50303500.0  33136130.0   97.20\n",
              "1130   98.68   98.55   98.97  ...  70722000.0  49687870.0  100.56\n",
              "860   127.98  128.31  129.13  ...  24460160.0  26784530.0  127.03\n",
              "1126  100.32   97.96   96.20  ...  63000140.0  79356010.0  100.55\n",
              "\n",
              "[879 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh17CfHqqTkp",
        "outputId": "a2cb0aeb-5af6-4941-bcb1-a5a8ec0d71cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "X_test_date"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open-1</th>\n",
              "      <th>Open-2</th>\n",
              "      <th>Open-3</th>\n",
              "      <th>High-1</th>\n",
              "      <th>High-2</th>\n",
              "      <th>High-3</th>\n",
              "      <th>Low-1</th>\n",
              "      <th>Low-2</th>\n",
              "      <th>Low-3</th>\n",
              "      <th>Volume-1</th>\n",
              "      <th>Volume-2</th>\n",
              "      <th>Volume-3</th>\n",
              "      <th>Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>225.46</td>\n",
              "      <td>214.52</td>\n",
              "      <td>220.42</td>\n",
              "      <td>226.35</td>\n",
              "      <td>219.50</td>\n",
              "      <td>222.88</td>\n",
              "      <td>216.05</td>\n",
              "      <td>212.32</td>\n",
              "      <td>216.84</td>\n",
              "      <td>41084070.0</td>\n",
              "      <td>52902320.0</td>\n",
              "      <td>39494770.0</td>\n",
              "      <td>10/09/18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>314.18</td>\n",
              "      <td>323.60</td>\n",
              "      <td>321.47</td>\n",
              "      <td>321.55</td>\n",
              "      <td>323.90</td>\n",
              "      <td>327.22</td>\n",
              "      <td>313.85</td>\n",
              "      <td>318.71</td>\n",
              "      <td>321.47</td>\n",
              "      <td>27337220.0</td>\n",
              "      <td>23580780.0</td>\n",
              "      <td>28432570.0</td>\n",
              "      <td>02/07/20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>273.61</td>\n",
              "      <td>275.87</td>\n",
              "      <td>277.20</td>\n",
              "      <td>277.90</td>\n",
              "      <td>281.75</td>\n",
              "      <td>283.01</td>\n",
              "      <td>272.20</td>\n",
              "      <td>274.87</td>\n",
              "      <td>277.00</td>\n",
              "      <td>29264340.0</td>\n",
              "      <td>31203580.0</td>\n",
              "      <td>31627180.0</td>\n",
              "      <td>04/21/2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>242.80</td>\n",
              "      <td>250.90</td>\n",
              "      <td>270.80</td>\n",
              "      <td>245.70</td>\n",
              "      <td>263.11</td>\n",
              "      <td>271.70</td>\n",
              "      <td>238.97</td>\n",
              "      <td>249.38</td>\n",
              "      <td>259.00</td>\n",
              "      <td>32470020.0</td>\n",
              "      <td>50455070.0</td>\n",
              "      <td>50721830.0</td>\n",
              "      <td>04/02/20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1151</th>\n",
              "      <td>118.98</td>\n",
              "      <td>117.52</td>\n",
              "      <td>117.64</td>\n",
              "      <td>119.86</td>\n",
              "      <td>118.60</td>\n",
              "      <td>117.69</td>\n",
              "      <td>117.81</td>\n",
              "      <td>116.86</td>\n",
              "      <td>115.08</td>\n",
              "      <td>32063100.0</td>\n",
              "      <td>34275420.0</td>\n",
              "      <td>46301930.0</td>\n",
              "      <td>12/04/15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>115.80</td>\n",
              "      <td>116.74</td>\n",
              "      <td>116.80</td>\n",
              "      <td>117.38</td>\n",
              "      <td>117.50</td>\n",
              "      <td>117.40</td>\n",
              "      <td>115.75</td>\n",
              "      <td>116.68</td>\n",
              "      <td>116.78</td>\n",
              "      <td>27756760.0</td>\n",
              "      <td>21337310.0</td>\n",
              "      <td>23724430.0</td>\n",
              "      <td>12/16/2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>752</th>\n",
              "      <td>144.11</td>\n",
              "      <td>144.73</td>\n",
              "      <td>145.87</td>\n",
              "      <td>145.95</td>\n",
              "      <td>145.85</td>\n",
              "      <td>146.18</td>\n",
              "      <td>143.37</td>\n",
              "      <td>144.38</td>\n",
              "      <td>144.82</td>\n",
              "      <td>21080580.0</td>\n",
              "      <td>18647220.0</td>\n",
              "      <td>24833800.0</td>\n",
              "      <td>07/07/17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>823</th>\n",
              "      <td>140.91</td>\n",
              "      <td>143.68</td>\n",
              "      <td>144.19</td>\n",
              "      <td>144.04</td>\n",
              "      <td>144.49</td>\n",
              "      <td>144.50</td>\n",
              "      <td>140.62</td>\n",
              "      <td>143.19</td>\n",
              "      <td>143.50</td>\n",
              "      <td>33348400.0</td>\n",
              "      <td>29174040.0</td>\n",
              "      <td>21189000.0</td>\n",
              "      <td>03/27/2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>144.53</td>\n",
              "      <td>148.70</td>\n",
              "      <td>149.56</td>\n",
              "      <td>148.55</td>\n",
              "      <td>148.83</td>\n",
              "      <td>151.82</td>\n",
              "      <td>143.80</td>\n",
              "      <td>145.90</td>\n",
              "      <td>148.52</td>\n",
              "      <td>57423650.0</td>\n",
              "      <td>54571440.0</td>\n",
              "      <td>40622910.0</td>\n",
              "      <td>01/03/19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>201.30</td>\n",
              "      <td>199.62</td>\n",
              "      <td>201.02</td>\n",
              "      <td>202.76</td>\n",
              "      <td>202.05</td>\n",
              "      <td>212.14</td>\n",
              "      <td>199.29</td>\n",
              "      <td>199.15</td>\n",
              "      <td>200.83</td>\n",
              "      <td>24619750.0</td>\n",
              "      <td>22481890.0</td>\n",
              "      <td>47539790.0</td>\n",
              "      <td>08/08/19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>377 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Open-1  Open-2  Open-3  ...    Volume-2    Volume-3        Date\n",
              "435   225.46  214.52  220.42  ...  52902320.0  39494770.0    10/09/18\n",
              "101   314.18  323.60  321.47  ...  23580780.0  28432570.0    02/07/20\n",
              "51    273.61  275.87  277.20  ...  31203580.0  31627180.0  04/21/2020\n",
              "63    242.80  250.90  270.80  ...  50455070.0  50721830.0    04/02/20\n",
              "1151  118.98  117.52  117.64  ...  34275420.0  46301930.0    12/04/15\n",
              "...      ...     ...     ...  ...         ...         ...         ...\n",
              "890   115.80  116.74  116.80  ...  21337310.0  23724430.0  12/16/2016\n",
              "752   144.11  144.73  145.87  ...  18647220.0  24833800.0    07/07/17\n",
              "823   140.91  143.68  144.19  ...  29174040.0  21189000.0  03/27/2017\n",
              "377   144.53  148.70  149.56  ...  54571440.0  40622910.0    01/03/19\n",
              "227   201.30  199.62  201.02  ...  22481890.0  47539790.0    08/08/19\n",
              "\n",
              "[377 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCnPgz9AqV0g",
        "outputId": "301eb54a-3660-4878-8e4d-aa9045714f16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "X_test_date['Date'] =pd.to_datetime(X_test_date.Date)\n",
        "X_test_date=X_test_date.sort_values(by='Date') # This now sorts in date order\n",
        "X_test_date"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open-1</th>\n",
              "      <th>Open-2</th>\n",
              "      <th>Open-3</th>\n",
              "      <th>High-1</th>\n",
              "      <th>High-2</th>\n",
              "      <th>High-3</th>\n",
              "      <th>Low-1</th>\n",
              "      <th>Low-2</th>\n",
              "      <th>Low-3</th>\n",
              "      <th>Volume-1</th>\n",
              "      <th>Volume-2</th>\n",
              "      <th>Volume-3</th>\n",
              "      <th>Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1255</th>\n",
              "      <td>121.94</td>\n",
              "      <td>125.03</td>\n",
              "      <td>126.04</td>\n",
              "      <td>123.85</td>\n",
              "      <td>125.76</td>\n",
              "      <td>126.37</td>\n",
              "      <td>121.21</td>\n",
              "      <td>124.32</td>\n",
              "      <td>125.04</td>\n",
              "      <td>61292800.0</td>\n",
              "      <td>41365600.0</td>\n",
              "      <td>31695870.0</td>\n",
              "      <td>2015-07-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1251</th>\n",
              "      <td>127.74</td>\n",
              "      <td>129.08</td>\n",
              "      <td>130.97</td>\n",
              "      <td>128.57</td>\n",
              "      <td>129.62</td>\n",
              "      <td>132.97</td>\n",
              "      <td>127.35</td>\n",
              "      <td>128.31</td>\n",
              "      <td>130.70</td>\n",
              "      <td>35987630.0</td>\n",
              "      <td>45970470.0</td>\n",
              "      <td>55204920.0</td>\n",
              "      <td>2015-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1249</th>\n",
              "      <td>130.97</td>\n",
              "      <td>132.85</td>\n",
              "      <td>121.99</td>\n",
              "      <td>132.97</td>\n",
              "      <td>132.92</td>\n",
              "      <td>125.50</td>\n",
              "      <td>130.70</td>\n",
              "      <td>130.32</td>\n",
              "      <td>121.99</td>\n",
              "      <td>55204920.0</td>\n",
              "      <td>73006780.0</td>\n",
              "      <td>115288400.0</td>\n",
              "      <td>2015-07-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1248</th>\n",
              "      <td>132.85</td>\n",
              "      <td>121.99</td>\n",
              "      <td>126.20</td>\n",
              "      <td>132.92</td>\n",
              "      <td>125.50</td>\n",
              "      <td>127.09</td>\n",
              "      <td>130.32</td>\n",
              "      <td>121.99</td>\n",
              "      <td>125.06</td>\n",
              "      <td>73006780.0</td>\n",
              "      <td>115288400.0</td>\n",
              "      <td>50832950.0</td>\n",
              "      <td>2015-07-20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1247</th>\n",
              "      <td>121.99</td>\n",
              "      <td>126.20</td>\n",
              "      <td>125.32</td>\n",
              "      <td>125.50</td>\n",
              "      <td>127.09</td>\n",
              "      <td>125.74</td>\n",
              "      <td>121.99</td>\n",
              "      <td>125.06</td>\n",
              "      <td>123.90</td>\n",
              "      <td>115288400.0</td>\n",
              "      <td>50832950.0</td>\n",
              "      <td>42090320.0</td>\n",
              "      <td>2015-07-21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>315.77</td>\n",
              "      <td>323.50</td>\n",
              "      <td>316.14</td>\n",
              "      <td>319.23</td>\n",
              "      <td>324.24</td>\n",
              "      <td>318.71</td>\n",
              "      <td>315.35</td>\n",
              "      <td>316.50</td>\n",
              "      <td>313.09</td>\n",
              "      <td>20450750.0</td>\n",
              "      <td>31380450.0</td>\n",
              "      <td>28236270.0</td>\n",
              "      <td>2020-05-21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>320.75</td>\n",
              "      <td>324.66</td>\n",
              "      <td>324.39</td>\n",
              "      <td>323.44</td>\n",
              "      <td>326.20</td>\n",
              "      <td>325.62</td>\n",
              "      <td>318.93</td>\n",
              "      <td>322.30</td>\n",
              "      <td>320.78</td>\n",
              "      <td>21910700.0</td>\n",
              "      <td>26122800.0</td>\n",
              "      <td>21890090.0</td>\n",
              "      <td>2020-06-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>354.64</td>\n",
              "      <td>351.34</td>\n",
              "      <td>364.00</td>\n",
              "      <td>356.56</td>\n",
              "      <td>359.46</td>\n",
              "      <td>372.38</td>\n",
              "      <td>345.15</td>\n",
              "      <td>351.15</td>\n",
              "      <td>362.27</td>\n",
              "      <td>66118950.0</td>\n",
              "      <td>33861320.0</td>\n",
              "      <td>53038870.0</td>\n",
              "      <td>2020-06-18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>364.41</td>\n",
              "      <td>353.25</td>\n",
              "      <td>360.08</td>\n",
              "      <td>365.32</td>\n",
              "      <td>362.17</td>\n",
              "      <td>365.98</td>\n",
              "      <td>353.02</td>\n",
              "      <td>351.28</td>\n",
              "      <td>360.00</td>\n",
              "      <td>51314210.0</td>\n",
              "      <td>32661520.0</td>\n",
              "      <td>35055820.0</td>\n",
              "      <td>2020-06-25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>360.08</td>\n",
              "      <td>365.12</td>\n",
              "      <td>367.85</td>\n",
              "      <td>365.98</td>\n",
              "      <td>367.36</td>\n",
              "      <td>370.47</td>\n",
              "      <td>360.00</td>\n",
              "      <td>363.91</td>\n",
              "      <td>363.64</td>\n",
              "      <td>35055820.0</td>\n",
              "      <td>27684310.0</td>\n",
              "      <td>28510370.0</td>\n",
              "      <td>2020-06-29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>377 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Open-1  Open-2  Open-3  ...     Volume-2     Volume-3       Date\n",
              "1255  121.94  125.03  126.04  ...   41365600.0   31695870.0 2015-07-09\n",
              "1251  127.74  129.08  130.97  ...   45970470.0   55204920.0 2015-07-15\n",
              "1249  130.97  132.85  121.99  ...   73006780.0  115288400.0 2015-07-17\n",
              "1248  132.85  121.99  126.20  ...  115288400.0   50832950.0 2015-07-20\n",
              "1247  121.99  126.20  125.32  ...   50832950.0   42090320.0 2015-07-21\n",
              "...      ...     ...     ...  ...          ...          ...        ...\n",
              "29    315.77  323.50  316.14  ...   31380450.0   28236270.0 2020-05-21\n",
              "23    320.75  324.66  324.39  ...   26122800.0   21890090.0 2020-06-01\n",
              "10    354.64  351.34  364.00  ...   33861320.0   53038870.0 2020-06-18\n",
              "5     364.41  353.25  360.08  ...   32661520.0   35055820.0 2020-06-25\n",
              "3     360.08  365.12  367.85  ...   27684310.0   28510370.0 2020-06-29\n",
              "\n",
              "[377 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwHUY_2Du8uI"
      },
      "source": [
        "y_test = y_test.reindex(X_test_date.index)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN0A1Z3spY_o",
        "outputId": "37c0b043-e961-48a8-94d1-be6777559c23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "X_test=X_test_date.drop(['Date'],axis=1)\n",
        "X_test"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open-1</th>\n",
              "      <th>Open-2</th>\n",
              "      <th>Open-3</th>\n",
              "      <th>High-1</th>\n",
              "      <th>High-2</th>\n",
              "      <th>High-3</th>\n",
              "      <th>Low-1</th>\n",
              "      <th>Low-2</th>\n",
              "      <th>Low-3</th>\n",
              "      <th>Volume-1</th>\n",
              "      <th>Volume-2</th>\n",
              "      <th>Volume-3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1255</th>\n",
              "      <td>121.94</td>\n",
              "      <td>125.03</td>\n",
              "      <td>126.04</td>\n",
              "      <td>123.85</td>\n",
              "      <td>125.76</td>\n",
              "      <td>126.37</td>\n",
              "      <td>121.21</td>\n",
              "      <td>124.32</td>\n",
              "      <td>125.04</td>\n",
              "      <td>61292800.0</td>\n",
              "      <td>41365600.0</td>\n",
              "      <td>31695870.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1251</th>\n",
              "      <td>127.74</td>\n",
              "      <td>129.08</td>\n",
              "      <td>130.97</td>\n",
              "      <td>128.57</td>\n",
              "      <td>129.62</td>\n",
              "      <td>132.97</td>\n",
              "      <td>127.35</td>\n",
              "      <td>128.31</td>\n",
              "      <td>130.70</td>\n",
              "      <td>35987630.0</td>\n",
              "      <td>45970470.0</td>\n",
              "      <td>55204920.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1249</th>\n",
              "      <td>130.97</td>\n",
              "      <td>132.85</td>\n",
              "      <td>121.99</td>\n",
              "      <td>132.97</td>\n",
              "      <td>132.92</td>\n",
              "      <td>125.50</td>\n",
              "      <td>130.70</td>\n",
              "      <td>130.32</td>\n",
              "      <td>121.99</td>\n",
              "      <td>55204920.0</td>\n",
              "      <td>73006780.0</td>\n",
              "      <td>115288400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1248</th>\n",
              "      <td>132.85</td>\n",
              "      <td>121.99</td>\n",
              "      <td>126.20</td>\n",
              "      <td>132.92</td>\n",
              "      <td>125.50</td>\n",
              "      <td>127.09</td>\n",
              "      <td>130.32</td>\n",
              "      <td>121.99</td>\n",
              "      <td>125.06</td>\n",
              "      <td>73006780.0</td>\n",
              "      <td>115288400.0</td>\n",
              "      <td>50832950.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1247</th>\n",
              "      <td>121.99</td>\n",
              "      <td>126.20</td>\n",
              "      <td>125.32</td>\n",
              "      <td>125.50</td>\n",
              "      <td>127.09</td>\n",
              "      <td>125.74</td>\n",
              "      <td>121.99</td>\n",
              "      <td>125.06</td>\n",
              "      <td>123.90</td>\n",
              "      <td>115288400.0</td>\n",
              "      <td>50832950.0</td>\n",
              "      <td>42090320.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>315.77</td>\n",
              "      <td>323.50</td>\n",
              "      <td>316.14</td>\n",
              "      <td>319.23</td>\n",
              "      <td>324.24</td>\n",
              "      <td>318.71</td>\n",
              "      <td>315.35</td>\n",
              "      <td>316.50</td>\n",
              "      <td>313.09</td>\n",
              "      <td>20450750.0</td>\n",
              "      <td>31380450.0</td>\n",
              "      <td>28236270.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>320.75</td>\n",
              "      <td>324.66</td>\n",
              "      <td>324.39</td>\n",
              "      <td>323.44</td>\n",
              "      <td>326.20</td>\n",
              "      <td>325.62</td>\n",
              "      <td>318.93</td>\n",
              "      <td>322.30</td>\n",
              "      <td>320.78</td>\n",
              "      <td>21910700.0</td>\n",
              "      <td>26122800.0</td>\n",
              "      <td>21890090.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>354.64</td>\n",
              "      <td>351.34</td>\n",
              "      <td>364.00</td>\n",
              "      <td>356.56</td>\n",
              "      <td>359.46</td>\n",
              "      <td>372.38</td>\n",
              "      <td>345.15</td>\n",
              "      <td>351.15</td>\n",
              "      <td>362.27</td>\n",
              "      <td>66118950.0</td>\n",
              "      <td>33861320.0</td>\n",
              "      <td>53038870.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>364.41</td>\n",
              "      <td>353.25</td>\n",
              "      <td>360.08</td>\n",
              "      <td>365.32</td>\n",
              "      <td>362.17</td>\n",
              "      <td>365.98</td>\n",
              "      <td>353.02</td>\n",
              "      <td>351.28</td>\n",
              "      <td>360.00</td>\n",
              "      <td>51314210.0</td>\n",
              "      <td>32661520.0</td>\n",
              "      <td>35055820.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>360.08</td>\n",
              "      <td>365.12</td>\n",
              "      <td>367.85</td>\n",
              "      <td>365.98</td>\n",
              "      <td>367.36</td>\n",
              "      <td>370.47</td>\n",
              "      <td>360.00</td>\n",
              "      <td>363.91</td>\n",
              "      <td>363.64</td>\n",
              "      <td>35055820.0</td>\n",
              "      <td>27684310.0</td>\n",
              "      <td>28510370.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>377 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Open-1  Open-2  Open-3  ...     Volume-1     Volume-2     Volume-3\n",
              "1255  121.94  125.03  126.04  ...   61292800.0   41365600.0   31695870.0\n",
              "1251  127.74  129.08  130.97  ...   35987630.0   45970470.0   55204920.0\n",
              "1249  130.97  132.85  121.99  ...   55204920.0   73006780.0  115288400.0\n",
              "1248  132.85  121.99  126.20  ...   73006780.0  115288400.0   50832950.0\n",
              "1247  121.99  126.20  125.32  ...  115288400.0   50832950.0   42090320.0\n",
              "...      ...     ...     ...  ...          ...          ...          ...\n",
              "29    315.77  323.50  316.14  ...   20450750.0   31380450.0   28236270.0\n",
              "23    320.75  324.66  324.39  ...   21910700.0   26122800.0   21890090.0\n",
              "10    354.64  351.34  364.00  ...   66118950.0   33861320.0   53038870.0\n",
              "5     364.41  353.25  360.08  ...   51314210.0   32661520.0   35055820.0\n",
              "3     360.08  365.12  367.85  ...   35055820.0   27684310.0   28510370.0\n",
              "\n",
              "[377 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17-Vz0nVPOOP"
      },
      "source": [
        "test_data=pd.concat([X_test,y_test],axis=1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdDyVPadPXfI",
        "outputId": "26a87d2f-dcbd-4781-a322-2a9f02476709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "test_data"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open-1</th>\n",
              "      <th>Open-2</th>\n",
              "      <th>Open-3</th>\n",
              "      <th>High-1</th>\n",
              "      <th>High-2</th>\n",
              "      <th>High-3</th>\n",
              "      <th>Low-1</th>\n",
              "      <th>Low-2</th>\n",
              "      <th>Low-3</th>\n",
              "      <th>Volume-1</th>\n",
              "      <th>Volume-2</th>\n",
              "      <th>Volume-3</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1255</th>\n",
              "      <td>121.94</td>\n",
              "      <td>125.03</td>\n",
              "      <td>126.04</td>\n",
              "      <td>123.85</td>\n",
              "      <td>125.76</td>\n",
              "      <td>126.37</td>\n",
              "      <td>121.21</td>\n",
              "      <td>124.32</td>\n",
              "      <td>125.04</td>\n",
              "      <td>61292800.0</td>\n",
              "      <td>41365600.0</td>\n",
              "      <td>31695870.0</td>\n",
              "      <td>123.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1251</th>\n",
              "      <td>127.74</td>\n",
              "      <td>129.08</td>\n",
              "      <td>130.97</td>\n",
              "      <td>128.57</td>\n",
              "      <td>129.62</td>\n",
              "      <td>132.97</td>\n",
              "      <td>127.35</td>\n",
              "      <td>128.31</td>\n",
              "      <td>130.70</td>\n",
              "      <td>35987630.0</td>\n",
              "      <td>45970470.0</td>\n",
              "      <td>55204920.0</td>\n",
              "      <td>125.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1249</th>\n",
              "      <td>130.97</td>\n",
              "      <td>132.85</td>\n",
              "      <td>121.99</td>\n",
              "      <td>132.97</td>\n",
              "      <td>132.92</td>\n",
              "      <td>125.50</td>\n",
              "      <td>130.70</td>\n",
              "      <td>130.32</td>\n",
              "      <td>121.99</td>\n",
              "      <td>55204920.0</td>\n",
              "      <td>73006780.0</td>\n",
              "      <td>115288400.0</td>\n",
              "      <td>129.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1248</th>\n",
              "      <td>132.85</td>\n",
              "      <td>121.99</td>\n",
              "      <td>126.20</td>\n",
              "      <td>132.92</td>\n",
              "      <td>125.50</td>\n",
              "      <td>127.09</td>\n",
              "      <td>130.32</td>\n",
              "      <td>121.99</td>\n",
              "      <td>125.06</td>\n",
              "      <td>73006780.0</td>\n",
              "      <td>115288400.0</td>\n",
              "      <td>50832950.0</td>\n",
              "      <td>130.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1247</th>\n",
              "      <td>121.99</td>\n",
              "      <td>126.20</td>\n",
              "      <td>125.32</td>\n",
              "      <td>125.50</td>\n",
              "      <td>127.09</td>\n",
              "      <td>125.74</td>\n",
              "      <td>121.99</td>\n",
              "      <td>125.06</td>\n",
              "      <td>123.90</td>\n",
              "      <td>115288400.0</td>\n",
              "      <td>50832950.0</td>\n",
              "      <td>42090320.0</td>\n",
              "      <td>132.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>315.77</td>\n",
              "      <td>323.50</td>\n",
              "      <td>316.14</td>\n",
              "      <td>319.23</td>\n",
              "      <td>324.24</td>\n",
              "      <td>318.71</td>\n",
              "      <td>315.35</td>\n",
              "      <td>316.50</td>\n",
              "      <td>313.09</td>\n",
              "      <td>20450750.0</td>\n",
              "      <td>31380450.0</td>\n",
              "      <td>28236270.0</td>\n",
              "      <td>318.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>320.75</td>\n",
              "      <td>324.66</td>\n",
              "      <td>324.39</td>\n",
              "      <td>323.44</td>\n",
              "      <td>326.20</td>\n",
              "      <td>325.62</td>\n",
              "      <td>318.93</td>\n",
              "      <td>322.30</td>\n",
              "      <td>320.78</td>\n",
              "      <td>21910700.0</td>\n",
              "      <td>26122800.0</td>\n",
              "      <td>21890090.0</td>\n",
              "      <td>317.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>354.64</td>\n",
              "      <td>351.34</td>\n",
              "      <td>364.00</td>\n",
              "      <td>356.56</td>\n",
              "      <td>359.46</td>\n",
              "      <td>372.38</td>\n",
              "      <td>345.15</td>\n",
              "      <td>351.15</td>\n",
              "      <td>362.27</td>\n",
              "      <td>66118950.0</td>\n",
              "      <td>33861320.0</td>\n",
              "      <td>53038870.0</td>\n",
              "      <td>351.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>364.41</td>\n",
              "      <td>353.25</td>\n",
              "      <td>360.08</td>\n",
              "      <td>365.32</td>\n",
              "      <td>362.17</td>\n",
              "      <td>365.98</td>\n",
              "      <td>353.02</td>\n",
              "      <td>351.28</td>\n",
              "      <td>360.00</td>\n",
              "      <td>51314210.0</td>\n",
              "      <td>32661520.0</td>\n",
              "      <td>35055820.0</td>\n",
              "      <td>360.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>360.08</td>\n",
              "      <td>365.12</td>\n",
              "      <td>367.85</td>\n",
              "      <td>365.98</td>\n",
              "      <td>367.36</td>\n",
              "      <td>370.47</td>\n",
              "      <td>360.00</td>\n",
              "      <td>363.91</td>\n",
              "      <td>363.64</td>\n",
              "      <td>35055820.0</td>\n",
              "      <td>27684310.0</td>\n",
              "      <td>28510370.0</td>\n",
              "      <td>353.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>377 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Open-1  Open-2  Open-3  ...     Volume-2     Volume-3  Target\n",
              "1255  121.94  125.03  126.04  ...   41365600.0   31695870.0  123.85\n",
              "1251  127.74  129.08  130.97  ...   45970470.0   55204920.0  125.72\n",
              "1249  130.97  132.85  121.99  ...   73006780.0  115288400.0  129.08\n",
              "1248  132.85  121.99  126.20  ...  115288400.0   50832950.0  130.97\n",
              "1247  121.99  126.20  125.32  ...   50832950.0   42090320.0  132.85\n",
              "...      ...     ...     ...  ...          ...          ...     ...\n",
              "29    315.77  323.50  316.14  ...   31380450.0   28236270.0  318.66\n",
              "23    320.75  324.66  324.39  ...   26122800.0   21890090.0  317.75\n",
              "10    354.64  351.34  364.00  ...   33861320.0   53038870.0  351.41\n",
              "5     364.41  353.25  360.08  ...   32661520.0   35055820.0  360.70\n",
              "3     360.08  365.12  367.85  ...   27684310.0   28510370.0  353.25\n",
              "\n",
              "[377 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4eLJBjxPYiW"
      },
      "source": [
        "train_data.to_csv(r'train.csv', index = False, header=True)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maEcPl7YQMHa"
      },
      "source": [
        "test_data.to_csv(r'test.csv', index = False, header=True)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INnBZjeyQjwa"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from keras.layers import LSTM, SimpleRNN, GRU\n",
        "from keras import callbacks\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF7Z6fuJSU21"
      },
      "source": [
        "#scaling the dataset using minmaxscaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "X_train=scaler.fit_transform(X_train)\n",
        "X_test=scaler.transform(X_test)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW63l-aI5aRV"
      },
      "source": [
        "#saving the scaler to apply it on the test dataset\n",
        "import pickle\n",
        "with open('scaler_RNN_model','wb') as file_pick:\n",
        "  pickle.dump(scaler,file_pick)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo7kmXPTRZ7Y"
      },
      "source": [
        "#numpy array conversion\n",
        "X_train=np.array(X_train)\n",
        "X_test=np.array(X_test)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t-_ugcpRArl"
      },
      "source": [
        "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
        "X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
        "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y52LE0LRpgk",
        "outputId": "1ce08ea2-b372-43dd-a0b9-4bdaaed53d0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape[0],X_train.shape[1]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(879, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic_1I2AeRXTz"
      },
      "source": [
        "model=Sequential()\n",
        "#adding LSTM layer with 50 LSTM units\n",
        "model.add(LSTM(50,return_sequences=True,input_shape=(12,1)))\n",
        "#adding LSTM layer with 50 LSTM units\n",
        "model.add(LSTM(50,return_sequences=True))\n",
        "#adding LSTM layer with 50 LSTM units\n",
        "model.add(LSTM(50))\n",
        "#adding dense layer\n",
        "model.add(Dense(1))\n",
        "'''\n",
        "\t'mean_squared_error' has been used as loss function\n",
        "\tOptimizer: Here adam optimizer has been used. Adam is an adaptive\n",
        "\tlearning rate optimization algorithm that’s been designed specifically for\n",
        "\ttraining deep neural networks.\n",
        "'''\n",
        "model.compile(loss='mean_squared_error',optimizer='adam')\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto',\n",
        "      restore_best_weights=True)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuk2dYxAR7tJ",
        "outputId": "5aeb98d7-ddc4-4607-8f40-4401bc6e5864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 12, 50)            10400     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 12, 50)            20200     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 50)                20200     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 50,851\n",
            "Trainable params: 50,851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUULwXWzSAQ4",
        "outputId": "edc7155c-a617-4279-f2b5-b27edb86db19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "lstm_out = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1500,batch_size=64,verbose=1)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1500\n",
            "14/14 [==============================] - 1s 70ms/step - loss: 33504.0742 - val_loss: 32890.6211\n",
            "Epoch 2/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 32088.0684 - val_loss: 30788.3242\n",
            "Epoch 3/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 30630.4688 - val_loss: 29985.7832\n",
            "Epoch 4/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 30058.0859 - val_loss: 29592.8887\n",
            "Epoch 5/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 29716.9629 - val_loss: 29282.4375\n",
            "Epoch 6/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 29421.8086 - val_loss: 28999.1934\n",
            "Epoch 7/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 29149.6523 - val_loss: 28728.4434\n",
            "Epoch 8/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 28885.4082 - val_loss: 28469.9922\n",
            "Epoch 9/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 28632.7832 - val_loss: 28216.9238\n",
            "Epoch 10/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 28383.0488 - val_loss: 27972.9492\n",
            "Epoch 11/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 28142.6738 - val_loss: 27730.5059\n",
            "Epoch 12/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 27903.6738 - val_loss: 27493.3555\n",
            "Epoch 13/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 27669.0312 - val_loss: 27260.4766\n",
            "Epoch 14/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 27439.4297 - val_loss: 27029.0391\n",
            "Epoch 15/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 27211.7852 - val_loss: 26800.8691\n",
            "Epoch 16/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 26985.8574 - val_loss: 26576.9609\n",
            "Epoch 17/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 26764.5645 - val_loss: 26354.0078\n",
            "Epoch 18/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 26544.0371 - val_loss: 26134.5840\n",
            "Epoch 19/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 26327.0801 - val_loss: 25917.3496\n",
            "Epoch 20/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 26113.4375 - val_loss: 25700.5781\n",
            "Epoch 21/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 25899.2227 - val_loss: 25487.7695\n",
            "Epoch 22/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 25688.6875 - val_loss: 25276.9922\n",
            "Epoch 23/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 25480.5391 - val_loss: 25067.4590\n",
            "Epoch 24/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 25272.7539 - val_loss: 24861.3477\n",
            "Epoch 25/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 25068.5508 - val_loss: 24656.3125\n",
            "Epoch 26/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 24866.1055 - val_loss: 24452.1426\n",
            "Epoch 27/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 24664.3086 - val_loss: 24250.3535\n",
            "Epoch 28/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 24464.0859 - val_loss: 24050.8418\n",
            "Epoch 29/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 24268.2305 - val_loss: 23850.3496\n",
            "Epoch 30/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 24069.8203 - val_loss: 23654.5625\n",
            "Epoch 31/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 23876.2578 - val_loss: 23458.3711\n",
            "Epoch 32/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 23681.3926 - val_loss: 23266.2969\n",
            "Epoch 33/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 23492.1191 - val_loss: 23072.9043\n",
            "Epoch 34/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 23300.6758 - val_loss: 22883.3359\n",
            "Epoch 35/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 23112.4590 - val_loss: 22695.0352\n",
            "Epoch 36/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 22926.0859 - val_loss: 22507.0195\n",
            "Epoch 37/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 22741.2793 - val_loss: 22319.5508\n",
            "Epoch 38/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 22555.0723 - val_loss: 22137.0508\n",
            "Epoch 39/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 22374.1289 - val_loss: 21953.3496\n",
            "Epoch 40/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 22192.6719 - val_loss: 21771.8730\n",
            "Epoch 41/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 22013.6406 - val_loss: 21590.7578\n",
            "Epoch 42/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 21835.3145 - val_loss: 21411.5020\n",
            "Epoch 43/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 21657.8789 - val_loss: 21234.4961\n",
            "Epoch 44/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 21481.8496 - val_loss: 21059.3105\n",
            "Epoch 45/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 21308.4004 - val_loss: 20883.6133\n",
            "Epoch 46/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 21135.4512 - val_loss: 20709.4707\n",
            "Epoch 47/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 20963.5957 - val_loss: 20537.2656\n",
            "Epoch 48/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 20793.5742 - val_loss: 20366.1113\n",
            "Epoch 49/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 20624.7500 - val_loss: 20196.5762\n",
            "Epoch 50/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 20456.6953 - val_loss: 20029.3535\n",
            "Epoch 51/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 20291.5156 - val_loss: 19861.8887\n",
            "Epoch 52/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 20125.3633 - val_loss: 19697.2461\n",
            "Epoch 53/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 19963.6465 - val_loss: 19531.1895\n",
            "Epoch 54/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 19799.1367 - val_loss: 19369.5059\n",
            "Epoch 55/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 19638.9648 - val_loss: 19207.3906\n",
            "Epoch 56/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 19479.6250 - val_loss: 19045.7949\n",
            "Epoch 57/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 19320.1406 - val_loss: 18886.4609\n",
            "Epoch 58/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 19161.7988 - val_loss: 18728.6074\n",
            "Epoch 59/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 19006.4473 - val_loss: 18570.7910\n",
            "Epoch 60/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 18849.5352 - val_loss: 18416.5410\n",
            "Epoch 61/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 18696.9277 - val_loss: 18261.5840\n",
            "Epoch 62/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 18543.9297 - val_loss: 18108.1426\n",
            "Epoch 63/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 18392.9023 - val_loss: 17955.1191\n",
            "Epoch 64/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 18241.7070 - val_loss: 17804.7461\n",
            "Epoch 65/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 18094.4258 - val_loss: 17653.0957\n",
            "Epoch 66/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 17944.4102 - val_loss: 17505.4961\n",
            "Epoch 67/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 17798.7773 - val_loss: 17357.3340\n",
            "Epoch 68/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 17652.5137 - val_loss: 17211.1426\n",
            "Epoch 69/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 17508.2520 - val_loss: 17066.3457\n",
            "Epoch 70/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 17364.2266 - val_loss: 16923.5664\n",
            "Epoch 71/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 17223.1016 - val_loss: 16779.9785\n",
            "Epoch 72/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 17081.6582 - val_loss: 16638.2051\n",
            "Epoch 73/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 16942.3066 - val_loss: 16496.9062\n",
            "Epoch 74/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 16803.6562 - val_loss: 16356.4805\n",
            "Epoch 75/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 16664.1074 - val_loss: 16219.9697\n",
            "Epoch 76/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 16529.3770 - val_loss: 16081.7852\n",
            "Epoch 77/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 16392.7676 - val_loss: 15946.3789\n",
            "Epoch 78/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 16259.1309 - val_loss: 15810.9600\n",
            "Epoch 79/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 16125.1025 - val_loss: 15677.3770\n",
            "Epoch 80/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 15994.0488 - val_loss: 15542.7256\n",
            "Epoch 81/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 15861.1240 - val_loss: 15411.0400\n",
            "Epoch 82/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 15731.1172 - val_loss: 15279.2812\n",
            "Epoch 83/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 15601.0352 - val_loss: 15149.8975\n",
            "Epoch 84/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 15473.0215 - val_loss: 15021.3105\n",
            "Epoch 85/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 15345.9863 - val_loss: 14893.2744\n",
            "Epoch 86/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 15220.1270 - val_loss: 14765.6406\n",
            "Epoch 87/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 15094.3721 - val_loss: 14639.8955\n",
            "Epoch 88/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 14969.6895 - val_loss: 14516.1729\n",
            "Epoch 89/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 14847.7295 - val_loss: 14392.0732\n",
            "Epoch 90/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 14725.0342 - val_loss: 14269.4629\n",
            "Epoch 91/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 14604.3887 - val_loss: 14147.3584\n",
            "Epoch 92/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 14483.9951 - val_loss: 14026.2441\n",
            "Epoch 93/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 14364.7939 - val_loss: 13906.0234\n",
            "Epoch 94/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 14246.2441 - val_loss: 13787.3975\n",
            "Epoch 95/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 14129.8828 - val_loss: 13668.7246\n",
            "Epoch 96/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 14011.9971 - val_loss: 13553.0039\n",
            "Epoch 97/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 13897.5850 - val_loss: 13436.9805\n",
            "Epoch 98/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 13783.9990 - val_loss: 13320.7588\n",
            "Epoch 99/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 13669.2188 - val_loss: 13207.3818\n",
            "Epoch 100/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 13557.4971 - val_loss: 13093.8301\n",
            "Epoch 101/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 13445.0508 - val_loss: 12982.1641\n",
            "Epoch 102/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 13335.0234 - val_loss: 12870.5371\n",
            "Epoch 103/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 13225.2041 - val_loss: 12759.9258\n",
            "Epoch 104/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 13116.9658 - val_loss: 12649.7119\n",
            "Epoch 105/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 13008.5186 - val_loss: 12541.5469\n",
            "Epoch 106/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 12902.2461 - val_loss: 12433.5254\n",
            "Epoch 107/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 12795.7305 - val_loss: 12327.2324\n",
            "Epoch 108/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 12690.8984 - val_loss: 12221.6025\n",
            "Epoch 109/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 12587.4385 - val_loss: 12116.2256\n",
            "Epoch 110/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 12482.3105 - val_loss: 12014.6025\n",
            "Epoch 111/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 12381.4678 - val_loss: 11911.5332\n",
            "Epoch 112/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 12280.4160 - val_loss: 11808.3643\n",
            "Epoch 113/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 12179.1953 - val_loss: 11706.7266\n",
            "Epoch 114/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 12079.0430 - val_loss: 11606.0957\n",
            "Epoch 115/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 11980.4678 - val_loss: 11506.0547\n",
            "Epoch 116/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 11882.0781 - val_loss: 11407.7559\n",
            "Epoch 117/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 11784.8369 - val_loss: 11310.3037\n",
            "Epoch 118/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 11688.6387 - val_loss: 11213.2070\n",
            "Epoch 119/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 11593.0898 - val_loss: 11116.9316\n",
            "Epoch 120/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 11498.2646 - val_loss: 11021.5820\n",
            "Epoch 121/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 11404.9365 - val_loss: 10926.2471\n",
            "Epoch 122/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 11311.4756 - val_loss: 10832.7314\n",
            "Epoch 123/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 11218.8262 - val_loss: 10740.7451\n",
            "Epoch 124/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 11128.0332 - val_loss: 10648.5215\n",
            "Epoch 125/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 11037.4922 - val_loss: 10557.3027\n",
            "Epoch 126/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 10948.2051 - val_loss: 10466.3096\n",
            "Epoch 127/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 10859.1611 - val_loss: 10376.7432\n",
            "Epoch 128/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 10771.4199 - val_loss: 10288.1113\n",
            "Epoch 129/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 10683.9795 - val_loss: 10200.8467\n",
            "Epoch 130/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 10597.7979 - val_loss: 10114.0488\n",
            "Epoch 131/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 10512.2646 - val_loss: 10028.0283\n",
            "Epoch 132/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 10427.7598 - val_loss: 9942.0771\n",
            "Epoch 133/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 10342.4971 - val_loss: 9858.6787\n",
            "Epoch 134/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 10261.6553 - val_loss: 9772.6992\n",
            "Epoch 135/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 10177.2910 - val_loss: 9690.1973\n",
            "Epoch 136/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 10096.5020 - val_loss: 9607.8672\n",
            "Epoch 137/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 10015.2734 - val_loss: 9526.9121\n",
            "Epoch 138/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 9936.1377 - val_loss: 9445.4512\n",
            "Epoch 139/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 9855.0137 - val_loss: 9367.3818\n",
            "Epoch 140/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 9777.9473 - val_loss: 9287.2529\n",
            "Epoch 141/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 9700.7656 - val_loss: 9207.3730\n",
            "Epoch 142/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 9622.3223 - val_loss: 9130.3438\n",
            "Epoch 143/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 9546.1270 - val_loss: 9054.0586\n",
            "Epoch 144/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 9471.6621 - val_loss: 8976.9375\n",
            "Epoch 145/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 9396.3857 - val_loss: 8901.1406\n",
            "Epoch 146/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 9322.2363 - val_loss: 8826.5439\n",
            "Epoch 147/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 9248.8936 - val_loss: 8752.9902\n",
            "Epoch 148/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 9176.6260 - val_loss: 8680.1406\n",
            "Epoch 149/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 9104.3281 - val_loss: 8608.8955\n",
            "Epoch 150/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 9034.2734 - val_loss: 8536.5098\n",
            "Epoch 151/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 8963.5117 - val_loss: 8464.9805\n",
            "Epoch 152/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 8893.6387 - val_loss: 8394.5547\n",
            "Epoch 153/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 8824.2051 - val_loss: 8325.0420\n",
            "Epoch 154/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 8755.8145 - val_loss: 8256.1562\n",
            "Epoch 155/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 8688.5225 - val_loss: 8187.4097\n",
            "Epoch 156/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 8621.4590 - val_loss: 8119.7280\n",
            "Epoch 157/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 8554.9326 - val_loss: 8053.1299\n",
            "Epoch 158/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 8489.2285 - val_loss: 7987.2705\n",
            "Epoch 159/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 8424.2559 - val_loss: 7921.9282\n",
            "Epoch 160/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 8360.4775 - val_loss: 7856.1074\n",
            "Epoch 161/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 8295.9932 - val_loss: 7792.1763\n",
            "Epoch 162/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 8234.1836 - val_loss: 7727.2412\n",
            "Epoch 163/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 8170.3262 - val_loss: 7665.2930\n",
            "Epoch 164/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 8109.1445 - val_loss: 7603.2017\n",
            "Epoch 165/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 8048.0923 - val_loss: 7541.6406\n",
            "Epoch 166/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 7988.6909 - val_loss: 7478.9800\n",
            "Epoch 167/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 7927.4424 - val_loss: 7419.2358\n",
            "Epoch 168/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 7868.8647 - val_loss: 7359.7393\n",
            "Epoch 169/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 7811.2935 - val_loss: 7299.6392\n",
            "Epoch 170/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 7752.3711 - val_loss: 7241.9458\n",
            "Epoch 171/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 7695.5425 - val_loss: 7184.4482\n",
            "Epoch 172/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 7639.0859 - val_loss: 7127.5591\n",
            "Epoch 173/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 7583.5474 - val_loss: 7070.9131\n",
            "Epoch 174/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 7527.9541 - val_loss: 7015.5781\n",
            "Epoch 175/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 7473.8057 - val_loss: 6960.2998\n",
            "Epoch 176/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 7419.8530 - val_loss: 6905.6226\n",
            "Epoch 177/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 7366.8701 - val_loss: 6851.3335\n",
            "Epoch 178/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 7313.8726 - val_loss: 6798.0835\n",
            "Epoch 179/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 7261.6929 - val_loss: 6745.6313\n",
            "Epoch 180/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 7210.4297 - val_loss: 6693.0439\n",
            "Epoch 181/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 7159.0278 - val_loss: 6641.5117\n",
            "Epoch 182/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 7109.0664 - val_loss: 6589.9497\n",
            "Epoch 183/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 7058.8545 - val_loss: 6539.5811\n",
            "Epoch 184/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 7009.4697 - val_loss: 6489.8857\n",
            "Epoch 185/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 6960.8970 - val_loss: 6440.5703\n",
            "Epoch 186/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 6912.7393 - val_loss: 6392.0244\n",
            "Epoch 187/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 6865.4136 - val_loss: 6344.0586\n",
            "Epoch 188/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 6819.1182 - val_loss: 6295.6890\n",
            "Epoch 189/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 6772.0479 - val_loss: 6248.9443\n",
            "Epoch 190/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 6726.1206 - val_loss: 6203.0591\n",
            "Epoch 191/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 6681.7212 - val_loss: 6156.6338\n",
            "Epoch 192/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 6635.9287 - val_loss: 6112.2075\n",
            "Epoch 193/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 6592.7852 - val_loss: 6066.9497\n",
            "Epoch 194/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 6548.6899 - val_loss: 6022.8477\n",
            "Epoch 195/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 6505.6714 - val_loss: 5979.0386\n",
            "Epoch 196/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 6462.6733 - val_loss: 5936.5186\n",
            "Epoch 197/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 6421.2183 - val_loss: 5893.7012\n",
            "Epoch 198/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 6379.6455 - val_loss: 5851.3130\n",
            "Epoch 199/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 6338.7036 - val_loss: 5809.4976\n",
            "Epoch 200/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 6298.1367 - val_loss: 5768.4033\n",
            "Epoch 201/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 6257.9385 - val_loss: 5728.2520\n",
            "Epoch 202/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 6218.8867 - val_loss: 5687.9536\n",
            "Epoch 203/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 6180.1895 - val_loss: 5647.8501\n",
            "Epoch 204/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 6140.9385 - val_loss: 5609.4316\n",
            "Epoch 205/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 6103.0039 - val_loss: 5571.3887\n",
            "Epoch 206/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 6066.2144 - val_loss: 5532.6006\n",
            "Epoch 207/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 6028.9214 - val_loss: 5494.9116\n",
            "Epoch 208/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5992.4487 - val_loss: 5457.7524\n",
            "Epoch 209/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 5956.3447 - val_loss: 5421.4077\n",
            "Epoch 210/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5921.0400 - val_loss: 5385.1221\n",
            "Epoch 211/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5885.5688 - val_loss: 5349.8589\n",
            "Epoch 212/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5851.1040 - val_loss: 5314.6948\n",
            "Epoch 213/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5817.0581 - val_loss: 5279.7827\n",
            "Epoch 214/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 5782.8462 - val_loss: 5246.0171\n",
            "Epoch 215/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5750.4380 - val_loss: 5211.2686\n",
            "Epoch 216/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5717.3062 - val_loss: 5177.7153\n",
            "Epoch 217/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5684.5732 - val_loss: 5145.2549\n",
            "Epoch 218/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5652.7832 - val_loss: 5113.3867\n",
            "Epoch 219/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 5622.7480 - val_loss: 5080.0542\n",
            "Epoch 220/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 5590.1069 - val_loss: 5049.2817\n",
            "Epoch 221/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5560.0898 - val_loss: 5018.1973\n",
            "Epoch 222/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5530.3721 - val_loss: 4987.3970\n",
            "Epoch 223/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5500.2236 - val_loss: 4957.8857\n",
            "Epoch 224/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5472.0537 - val_loss: 4927.3682\n",
            "Epoch 225/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5442.3608 - val_loss: 4898.6265\n",
            "Epoch 226/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5414.5918 - val_loss: 4869.3345\n",
            "Epoch 227/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5385.8369 - val_loss: 4841.8921\n",
            "Epoch 228/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5359.4424 - val_loss: 4813.1089\n",
            "Epoch 229/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5332.2368 - val_loss: 4785.1782\n",
            "Epoch 230/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 5304.7617 - val_loss: 4758.6704\n",
            "Epoch 231/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5278.9419 - val_loss: 4731.8271\n",
            "Epoch 232/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5253.1079 - val_loss: 4705.1807\n",
            "Epoch 233/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5227.7456 - val_loss: 4678.7495\n",
            "Epoch 234/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5202.4209 - val_loss: 4653.1377\n",
            "Epoch 235/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5177.6650 - val_loss: 4628.2139\n",
            "Epoch 236/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5153.5903 - val_loss: 4603.2427\n",
            "Epoch 237/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5129.7134 - val_loss: 4578.6719\n",
            "Epoch 238/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 5105.5850 - val_loss: 4555.2070\n",
            "Epoch 239/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 5083.1138 - val_loss: 4530.9160\n",
            "Epoch 240/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5059.7451 - val_loss: 4507.7212\n",
            "Epoch 241/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 5037.8242 - val_loss: 4484.2959\n",
            "Epoch 242/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 5014.9185 - val_loss: 4462.4136\n",
            "Epoch 243/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4994.3179 - val_loss: 4439.2515\n",
            "Epoch 244/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4972.2280 - val_loss: 4417.6855\n",
            "Epoch 245/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4951.5166 - val_loss: 4395.9580\n",
            "Epoch 246/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 4930.8228 - val_loss: 4374.7300\n",
            "Epoch 247/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4910.3921 - val_loss: 4353.9263\n",
            "Epoch 248/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4890.3008 - val_loss: 4333.5068\n",
            "Epoch 249/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 4871.2158 - val_loss: 4313.0542\n",
            "Epoch 250/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 4851.4868 - val_loss: 4293.6533\n",
            "Epoch 251/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 4832.9033 - val_loss: 4273.9741\n",
            "Epoch 252/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4814.1138 - val_loss: 4255.1367\n",
            "Epoch 253/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4795.8628 - val_loss: 4236.6978\n",
            "Epoch 254/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4778.7852 - val_loss: 4217.5747\n",
            "Epoch 255/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4759.9648 - val_loss: 4200.4478\n",
            "Epoch 256/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4743.3945 - val_loss: 4182.3115\n",
            "Epoch 257/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4726.3652 - val_loss: 4164.4092\n",
            "Epoch 258/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4709.1733 - val_loss: 4147.5059\n",
            "Epoch 259/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4692.9927 - val_loss: 4130.7051\n",
            "Epoch 260/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 4677.2383 - val_loss: 4113.7725\n",
            "Epoch 261/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 4661.0654 - val_loss: 4097.5977\n",
            "Epoch 262/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 4645.6279 - val_loss: 4081.4734\n",
            "Epoch 263/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4630.2666 - val_loss: 4065.7307\n",
            "Epoch 264/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4615.2593 - val_loss: 4050.3110\n",
            "Epoch 265/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4600.4062 - val_loss: 4035.2786\n",
            "Epoch 266/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4586.5874 - val_loss: 4019.6670\n",
            "Epoch 267/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4571.8477 - val_loss: 4004.9973\n",
            "Epoch 268/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 4557.6680 - val_loss: 3991.0908\n",
            "Epoch 269/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4544.2202 - val_loss: 3976.9609\n",
            "Epoch 270/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4530.9648 - val_loss: 3962.7886\n",
            "Epoch 271/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4517.2891 - val_loss: 3949.8640\n",
            "Epoch 272/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4505.4023 - val_loss: 3935.8354\n",
            "Epoch 273/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4492.2339 - val_loss: 3922.8469\n",
            "Epoch 274/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4479.9771 - val_loss: 3910.1057\n",
            "Epoch 275/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 4467.7905 - val_loss: 3897.8342\n",
            "Epoch 276/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4456.0728 - val_loss: 3885.5498\n",
            "Epoch 277/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4444.6289 - val_loss: 3873.3293\n",
            "Epoch 278/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 4433.2144 - val_loss: 3861.6140\n",
            "Epoch 279/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4422.2656 - val_loss: 3850.1443\n",
            "Epoch 280/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4411.3716 - val_loss: 3838.9297\n",
            "Epoch 281/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4401.0181 - val_loss: 3827.6785\n",
            "Epoch 282/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4390.3711 - val_loss: 3817.2678\n",
            "Epoch 283/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4380.3003 - val_loss: 3807.0908\n",
            "Epoch 284/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4370.6030 - val_loss: 3796.7991\n",
            "Epoch 285/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4360.6968 - val_loss: 3786.7256\n",
            "Epoch 286/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 4351.3579 - val_loss: 3776.0806\n",
            "Epoch 287/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4341.4331 - val_loss: 3766.5593\n",
            "Epoch 288/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4332.7080 - val_loss: 3756.5503\n",
            "Epoch 289/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4323.7021 - val_loss: 3746.9868\n",
            "Epoch 290/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4314.6724 - val_loss: 3738.3020\n",
            "Epoch 291/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4306.7319 - val_loss: 3729.0046\n",
            "Epoch 292/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4298.1274 - val_loss: 3720.3845\n",
            "Epoch 293/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 4290.3579 - val_loss: 3711.5271\n",
            "Epoch 294/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4281.8125 - val_loss: 3703.9641\n",
            "Epoch 295/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 4274.4038 - val_loss: 3696.0742\n",
            "Epoch 296/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4267.1064 - val_loss: 3687.9658\n",
            "Epoch 297/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 4259.7910 - val_loss: 3679.9907\n",
            "Epoch 298/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4252.2832 - val_loss: 3672.7021\n",
            "Epoch 299/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4245.3643 - val_loss: 3665.2100\n",
            "Epoch 300/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4238.7769 - val_loss: 3657.5315\n",
            "Epoch 301/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4231.5659 - val_loss: 3650.7278\n",
            "Epoch 302/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 4225.0596 - val_loss: 3644.0044\n",
            "Epoch 303/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4218.9893 - val_loss: 3636.9053\n",
            "Epoch 304/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4212.2676 - val_loss: 3630.6648\n",
            "Epoch 305/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4206.9473 - val_loss: 3623.4482\n",
            "Epoch 306/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4200.1870 - val_loss: 3617.5378\n",
            "Epoch 307/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 4194.6152 - val_loss: 3611.3794\n",
            "Epoch 308/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 4188.6470 - val_loss: 3605.8530\n",
            "Epoch 309/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 4183.7451 - val_loss: 3599.3774\n",
            "Epoch 310/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4178.2642 - val_loss: 3593.4312\n",
            "Epoch 311/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4172.7217 - val_loss: 3588.1646\n",
            "Epoch 312/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 4168.1060 - val_loss: 3582.4822\n",
            "Epoch 313/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4162.9272 - val_loss: 3577.2407\n",
            "Epoch 314/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 4158.1816 - val_loss: 3572.1321\n",
            "Epoch 315/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4153.4155 - val_loss: 3567.4871\n",
            "Epoch 316/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4148.9663 - val_loss: 3562.8994\n",
            "Epoch 317/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4144.8867 - val_loss: 3557.9053\n",
            "Epoch 318/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4140.3335 - val_loss: 3553.4490\n",
            "Epoch 319/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4136.2305 - val_loss: 3548.8826\n",
            "Epoch 320/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4132.2544 - val_loss: 3544.3779\n",
            "Epoch 321/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4128.1099 - val_loss: 3540.1313\n",
            "Epoch 322/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 4124.4722 - val_loss: 3535.6335\n",
            "Epoch 323/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4120.4780 - val_loss: 3531.6929\n",
            "Epoch 324/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4116.7168 - val_loss: 3528.0142\n",
            "Epoch 325/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4113.7256 - val_loss: 3523.6501\n",
            "Epoch 326/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4109.7881 - val_loss: 3520.1221\n",
            "Epoch 327/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4106.6396 - val_loss: 3516.4768\n",
            "Epoch 328/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4103.2808 - val_loss: 3513.1665\n",
            "Epoch 329/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 4100.3643 - val_loss: 3509.5859\n",
            "Epoch 330/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4097.1797 - val_loss: 3506.2000\n",
            "Epoch 331/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4094.2305 - val_loss: 3503.0557\n",
            "Epoch 332/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4091.4470 - val_loss: 3499.9053\n",
            "Epoch 333/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4088.6692 - val_loss: 3497.0093\n",
            "Epoch 334/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4086.2244 - val_loss: 3493.6670\n",
            "Epoch 335/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4083.4346 - val_loss: 3490.7034\n",
            "Epoch 336/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 4080.6970 - val_loss: 3488.1804\n",
            "Epoch 337/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 4078.6243 - val_loss: 3485.2739\n",
            "Epoch 338/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4076.5393 - val_loss: 3481.9817\n",
            "Epoch 339/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 4073.6963 - val_loss: 3480.0325\n",
            "Epoch 340/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4071.5251 - val_loss: 3477.6929\n",
            "Epoch 341/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 4069.4858 - val_loss: 3475.3899\n",
            "Epoch 342/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4067.1572 - val_loss: 3469.7405\n",
            "Epoch 343/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 3914.4192 - val_loss: 2705.7676\n",
            "Epoch 344/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2995.7134 - val_loss: 2506.5591\n",
            "Epoch 345/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2916.7139 - val_loss: 2472.4497\n",
            "Epoch 346/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2875.1055 - val_loss: 2433.1414\n",
            "Epoch 347/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2839.2693 - val_loss: 2402.7722\n",
            "Epoch 348/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2808.1265 - val_loss: 2377.5266\n",
            "Epoch 349/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2780.0769 - val_loss: 2346.3293\n",
            "Epoch 350/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 2749.0813 - val_loss: 2319.0715\n",
            "Epoch 351/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 2718.9851 - val_loss: 2291.4744\n",
            "Epoch 352/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2691.3347 - val_loss: 2265.5308\n",
            "Epoch 353/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2664.0759 - val_loss: 2241.5200\n",
            "Epoch 354/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2637.5671 - val_loss: 2214.2971\n",
            "Epoch 355/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2610.3931 - val_loss: 2194.1284\n",
            "Epoch 356/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2584.8740 - val_loss: 2165.2151\n",
            "Epoch 357/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2556.9338 - val_loss: 2142.2075\n",
            "Epoch 358/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 2531.8271 - val_loss: 2118.3186\n",
            "Epoch 359/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 2506.4036 - val_loss: 2094.8882\n",
            "Epoch 360/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2481.8396 - val_loss: 2072.8630\n",
            "Epoch 361/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2457.8074 - val_loss: 2049.8169\n",
            "Epoch 362/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2432.6763 - val_loss: 2027.1490\n",
            "Epoch 363/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2410.0312 - val_loss: 2004.9089\n",
            "Epoch 364/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2386.4844 - val_loss: 1982.9102\n",
            "Epoch 365/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2362.9734 - val_loss: 1962.2666\n",
            "Epoch 366/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2340.4524 - val_loss: 1941.2795\n",
            "Epoch 367/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2318.0530 - val_loss: 1921.0844\n",
            "Epoch 368/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2296.8167 - val_loss: 1900.1554\n",
            "Epoch 369/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2274.6436 - val_loss: 1879.2874\n",
            "Epoch 370/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 2251.9722 - val_loss: 1860.0839\n",
            "Epoch 371/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2230.5459 - val_loss: 1841.6519\n",
            "Epoch 372/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2210.7451 - val_loss: 1821.5059\n",
            "Epoch 373/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2189.4946 - val_loss: 1802.4064\n",
            "Epoch 374/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2168.2800 - val_loss: 1783.3458\n",
            "Epoch 375/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2147.9834 - val_loss: 1765.8329\n",
            "Epoch 376/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2129.0688 - val_loss: 1747.1603\n",
            "Epoch 377/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2109.4048 - val_loss: 1731.7860\n",
            "Epoch 378/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2089.5161 - val_loss: 1711.0985\n",
            "Epoch 379/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 2069.7761 - val_loss: 1694.7482\n",
            "Epoch 380/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 2050.8513 - val_loss: 1675.7034\n",
            "Epoch 381/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 2032.4275 - val_loss: 1659.2352\n",
            "Epoch 382/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 2015.1135 - val_loss: 1642.6050\n",
            "Epoch 383/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1997.9398 - val_loss: 1627.1041\n",
            "Epoch 384/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 1978.4802 - val_loss: 1609.6528\n",
            "Epoch 385/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1960.7316 - val_loss: 1594.8580\n",
            "Epoch 386/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1942.4451 - val_loss: 1577.2834\n",
            "Epoch 387/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 1924.7443 - val_loss: 1561.3749\n",
            "Epoch 388/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1910.8759 - val_loss: 1548.9045\n",
            "Epoch 389/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1891.3523 - val_loss: 1530.6648\n",
            "Epoch 390/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1873.3906 - val_loss: 1514.5360\n",
            "Epoch 391/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 1857.6243 - val_loss: 1501.5759\n",
            "Epoch 392/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 1841.0544 - val_loss: 1485.2047\n",
            "Epoch 393/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1825.4103 - val_loss: 1470.8226\n",
            "Epoch 394/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 1808.8872 - val_loss: 1455.8344\n",
            "Epoch 395/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1793.9325 - val_loss: 1442.5231\n",
            "Epoch 396/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1777.0002 - val_loss: 1429.2106\n",
            "Epoch 397/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1761.4146 - val_loss: 1414.1018\n",
            "Epoch 398/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 1746.4454 - val_loss: 1399.6187\n",
            "Epoch 399/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1730.5336 - val_loss: 1386.8536\n",
            "Epoch 400/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1716.1595 - val_loss: 1373.5430\n",
            "Epoch 401/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1700.9553 - val_loss: 1359.9985\n",
            "Epoch 402/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1686.1558 - val_loss: 1346.1296\n",
            "Epoch 403/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 1671.3252 - val_loss: 1333.3435\n",
            "Epoch 404/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1656.4916 - val_loss: 1320.7362\n",
            "Epoch 405/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1642.1486 - val_loss: 1308.3782\n",
            "Epoch 406/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1627.9380 - val_loss: 1296.2682\n",
            "Epoch 407/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1614.5531 - val_loss: 1283.3929\n",
            "Epoch 408/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1600.5345 - val_loss: 1270.5469\n",
            "Epoch 409/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1586.6387 - val_loss: 1259.2943\n",
            "Epoch 410/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 1572.8304 - val_loss: 1246.3361\n",
            "Epoch 411/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1559.5178 - val_loss: 1237.5906\n",
            "Epoch 412/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1547.3597 - val_loss: 1223.2870\n",
            "Epoch 413/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1533.2103 - val_loss: 1212.5483\n",
            "Epoch 414/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 1520.5044 - val_loss: 1202.6930\n",
            "Epoch 415/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1507.9818 - val_loss: 1189.0012\n",
            "Epoch 416/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1495.5029 - val_loss: 1177.1881\n",
            "Epoch 417/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1481.8398 - val_loss: 1166.9376\n",
            "Epoch 418/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1469.5494 - val_loss: 1155.7908\n",
            "Epoch 419/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1457.3485 - val_loss: 1145.4396\n",
            "Epoch 420/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1444.9266 - val_loss: 1135.3689\n",
            "Epoch 421/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 1432.9750 - val_loss: 1123.9675\n",
            "Epoch 422/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1421.4802 - val_loss: 1113.0677\n",
            "Epoch 423/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1409.6498 - val_loss: 1105.2455\n",
            "Epoch 424/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1397.5757 - val_loss: 1092.7620\n",
            "Epoch 425/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1384.9200 - val_loss: 1083.4761\n",
            "Epoch 426/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 1373.0027 - val_loss: 1072.6062\n",
            "Epoch 427/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1362.2793 - val_loss: 1063.4406\n",
            "Epoch 428/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1351.4143 - val_loss: 1052.6653\n",
            "Epoch 429/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1339.3510 - val_loss: 1043.3146\n",
            "Epoch 430/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1328.2632 - val_loss: 1034.2490\n",
            "Epoch 431/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1317.3304 - val_loss: 1026.7283\n",
            "Epoch 432/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1306.4189 - val_loss: 1014.3910\n",
            "Epoch 433/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1295.2102 - val_loss: 1009.2512\n",
            "Epoch 434/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1286.2122 - val_loss: 996.0052\n",
            "Epoch 435/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1274.4326 - val_loss: 987.2853\n",
            "Epoch 436/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1264.3472 - val_loss: 978.9389\n",
            "Epoch 437/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1252.8129 - val_loss: 970.3339\n",
            "Epoch 438/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1242.9836 - val_loss: 960.4394\n",
            "Epoch 439/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1231.4178 - val_loss: 951.6655\n",
            "Epoch 440/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 1221.7300 - val_loss: 942.2870\n",
            "Epoch 441/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1211.5100 - val_loss: 934.1198\n",
            "Epoch 442/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1201.2906 - val_loss: 925.5844\n",
            "Epoch 443/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 1191.0106 - val_loss: 917.2504\n",
            "Epoch 444/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1182.1066 - val_loss: 908.4483\n",
            "Epoch 445/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1171.6936 - val_loss: 902.5868\n",
            "Epoch 446/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1162.8438 - val_loss: 893.6822\n",
            "Epoch 447/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1152.5771 - val_loss: 886.2709\n",
            "Epoch 448/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 1143.7567 - val_loss: 875.2808\n",
            "Epoch 449/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1133.4972 - val_loss: 867.9066\n",
            "Epoch 450/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1123.4291 - val_loss: 860.3035\n",
            "Epoch 451/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1114.4622 - val_loss: 851.6788\n",
            "Epoch 452/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1105.0521 - val_loss: 844.9910\n",
            "Epoch 453/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1097.4412 - val_loss: 836.2692\n",
            "Epoch 454/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1088.8755 - val_loss: 829.0864\n",
            "Epoch 455/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1077.6133 - val_loss: 820.8160\n",
            "Epoch 456/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1068.2501 - val_loss: 814.4355\n",
            "Epoch 457/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1059.7822 - val_loss: 805.7334\n",
            "Epoch 458/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1050.9631 - val_loss: 798.8650\n",
            "Epoch 459/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1042.2112 - val_loss: 792.3788\n",
            "Epoch 460/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1034.0684 - val_loss: 784.2121\n",
            "Epoch 461/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1026.1102 - val_loss: 776.7515\n",
            "Epoch 462/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1016.0685 - val_loss: 770.6106\n",
            "Epoch 463/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1008.6702 - val_loss: 764.7977\n",
            "Epoch 464/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 999.9301 - val_loss: 757.5738\n",
            "Epoch 465/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 992.1062 - val_loss: 750.5276\n",
            "Epoch 466/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 983.5688 - val_loss: 742.6832\n",
            "Epoch 467/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 974.9125 - val_loss: 734.3495\n",
            "Epoch 468/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 967.1457 - val_loss: 731.3011\n",
            "Epoch 469/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 958.9754 - val_loss: 722.3650\n",
            "Epoch 470/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 951.2910 - val_loss: 718.6201\n",
            "Epoch 471/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 943.5941 - val_loss: 710.4985\n",
            "Epoch 472/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 935.8479 - val_loss: 705.5394\n",
            "Epoch 473/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 928.2356 - val_loss: 696.0216\n",
            "Epoch 474/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 919.7640 - val_loss: 689.6561\n",
            "Epoch 475/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 911.6439 - val_loss: 682.5313\n",
            "Epoch 476/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 903.9543 - val_loss: 676.3129\n",
            "Epoch 477/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 896.6654 - val_loss: 670.1689\n",
            "Epoch 478/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 889.2932 - val_loss: 663.6082\n",
            "Epoch 479/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 882.5483 - val_loss: 658.2239\n",
            "Epoch 480/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 874.8685 - val_loss: 652.0915\n",
            "Epoch 481/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 867.1020 - val_loss: 646.9465\n",
            "Epoch 482/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 860.6367 - val_loss: 639.7660\n",
            "Epoch 483/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 854.8293 - val_loss: 637.5903\n",
            "Epoch 484/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 847.0546 - val_loss: 628.1162\n",
            "Epoch 485/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 839.4400 - val_loss: 622.2885\n",
            "Epoch 486/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 831.8342 - val_loss: 616.2703\n",
            "Epoch 487/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 824.1646 - val_loss: 610.3717\n",
            "Epoch 488/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 818.0073 - val_loss: 603.8696\n",
            "Epoch 489/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 810.0514 - val_loss: 598.4235\n",
            "Epoch 490/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 803.2134 - val_loss: 592.6863\n",
            "Epoch 491/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 797.6665 - val_loss: 590.5153\n",
            "Epoch 492/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 793.1262 - val_loss: 582.0595\n",
            "Epoch 493/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 784.1617 - val_loss: 576.2470\n",
            "Epoch 494/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 776.8898 - val_loss: 573.6693\n",
            "Epoch 495/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 770.0159 - val_loss: 566.2957\n",
            "Epoch 496/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 762.7777 - val_loss: 559.3939\n",
            "Epoch 497/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 755.7262 - val_loss: 555.2258\n",
            "Epoch 498/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 749.3796 - val_loss: 548.7871\n",
            "Epoch 499/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 742.6196 - val_loss: 543.4270\n",
            "Epoch 500/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 736.6861 - val_loss: 538.0054\n",
            "Epoch 501/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 730.0626 - val_loss: 533.2236\n",
            "Epoch 502/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 723.8598 - val_loss: 528.2193\n",
            "Epoch 503/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 717.4182 - val_loss: 522.3680\n",
            "Epoch 504/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 710.9670 - val_loss: 517.5600\n",
            "Epoch 505/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 705.6080 - val_loss: 514.3394\n",
            "Epoch 506/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 699.2892 - val_loss: 508.3236\n",
            "Epoch 507/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 692.2565 - val_loss: 502.6906\n",
            "Epoch 508/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 686.7763 - val_loss: 497.9597\n",
            "Epoch 509/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 680.6605 - val_loss: 492.2787\n",
            "Epoch 510/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 674.1055 - val_loss: 487.3925\n",
            "Epoch 511/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 668.0978 - val_loss: 482.4188\n",
            "Epoch 512/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 663.3425 - val_loss: 477.6316\n",
            "Epoch 513/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 657.6780 - val_loss: 473.7627\n",
            "Epoch 514/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 651.7434 - val_loss: 468.5424\n",
            "Epoch 515/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 644.9492 - val_loss: 465.1971\n",
            "Epoch 516/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 639.9272 - val_loss: 460.8112\n",
            "Epoch 517/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 633.9811 - val_loss: 455.8269\n",
            "Epoch 518/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 628.7919 - val_loss: 452.2698\n",
            "Epoch 519/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 624.1948 - val_loss: 445.6359\n",
            "Epoch 520/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 616.8789 - val_loss: 440.8696\n",
            "Epoch 521/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 612.0947 - val_loss: 438.4139\n",
            "Epoch 522/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 607.4000 - val_loss: 439.0096\n",
            "Epoch 523/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 603.5220 - val_loss: 428.8983\n",
            "Epoch 524/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 596.0916 - val_loss: 423.6436\n",
            "Epoch 525/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 589.5619 - val_loss: 419.4857\n",
            "Epoch 526/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 583.3952 - val_loss: 413.8723\n",
            "Epoch 527/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 578.4507 - val_loss: 410.3895\n",
            "Epoch 528/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 573.6743 - val_loss: 405.7092\n",
            "Epoch 529/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 567.7800 - val_loss: 401.6166\n",
            "Epoch 530/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 563.6091 - val_loss: 399.0813\n",
            "Epoch 531/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 558.4473 - val_loss: 393.0945\n",
            "Epoch 532/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 552.9016 - val_loss: 392.5840\n",
            "Epoch 533/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 549.2211 - val_loss: 385.0629\n",
            "Epoch 534/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 542.4560 - val_loss: 380.8080\n",
            "Epoch 535/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 537.5691 - val_loss: 380.9271\n",
            "Epoch 536/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 534.2103 - val_loss: 377.2275\n",
            "Epoch 537/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 527.7723 - val_loss: 369.2217\n",
            "Epoch 538/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 523.9680 - val_loss: 365.0873\n",
            "Epoch 539/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 517.8807 - val_loss: 361.4360\n",
            "Epoch 540/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 513.1408 - val_loss: 358.7296\n",
            "Epoch 541/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 509.0519 - val_loss: 354.4267\n",
            "Epoch 542/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 504.2162 - val_loss: 351.6946\n",
            "Epoch 543/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 500.0049 - val_loss: 347.1920\n",
            "Epoch 544/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 495.2333 - val_loss: 343.6636\n",
            "Epoch 545/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 491.3408 - val_loss: 340.2986\n",
            "Epoch 546/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 485.1200 - val_loss: 336.4144\n",
            "Epoch 547/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 480.3407 - val_loss: 333.6859\n",
            "Epoch 548/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 477.4088 - val_loss: 328.9653\n",
            "Epoch 549/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 472.2484 - val_loss: 326.7149\n",
            "Epoch 550/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 468.3499 - val_loss: 323.0438\n",
            "Epoch 551/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 464.5346 - val_loss: 319.9714\n",
            "Epoch 552/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 460.8061 - val_loss: 317.0056\n",
            "Epoch 553/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 456.7842 - val_loss: 315.3115\n",
            "Epoch 554/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 451.5624 - val_loss: 310.9930\n",
            "Epoch 555/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 447.1948 - val_loss: 306.6457\n",
            "Epoch 556/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 443.3084 - val_loss: 303.5854\n",
            "Epoch 557/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 438.4377 - val_loss: 299.6100\n",
            "Epoch 558/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 435.4266 - val_loss: 297.4841\n",
            "Epoch 559/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 430.1362 - val_loss: 293.1313\n",
            "Epoch 560/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 425.3874 - val_loss: 290.7462\n",
            "Epoch 561/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 421.5060 - val_loss: 286.7026\n",
            "Epoch 562/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 417.5922 - val_loss: 284.2462\n",
            "Epoch 563/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 413.8769 - val_loss: 280.7216\n",
            "Epoch 564/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 409.7162 - val_loss: 277.9383\n",
            "Epoch 565/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 406.7221 - val_loss: 275.1680\n",
            "Epoch 566/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 403.0870 - val_loss: 273.9230\n",
            "Epoch 567/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 398.5638 - val_loss: 269.5742\n",
            "Epoch 568/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 394.9359 - val_loss: 267.6447\n",
            "Epoch 569/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 394.1242 - val_loss: 263.9631\n",
            "Epoch 570/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 389.3873 - val_loss: 262.1093\n",
            "Epoch 571/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 385.8205 - val_loss: 259.9053\n",
            "Epoch 572/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 382.8050 - val_loss: 253.8373\n",
            "Epoch 573/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 375.9977 - val_loss: 251.9810\n",
            "Epoch 574/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 374.1961 - val_loss: 252.0001\n",
            "Epoch 575/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 373.0973 - val_loss: 250.8451\n",
            "Epoch 576/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 366.6548 - val_loss: 244.1442\n",
            "Epoch 577/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 362.8985 - val_loss: 240.9746\n",
            "Epoch 578/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 358.7752 - val_loss: 238.0038\n",
            "Epoch 579/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 355.2412 - val_loss: 237.9718\n",
            "Epoch 580/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 353.0769 - val_loss: 233.4885\n",
            "Epoch 581/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 348.8817 - val_loss: 231.6081\n",
            "Epoch 582/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 345.2986 - val_loss: 228.6711\n",
            "Epoch 583/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 342.4128 - val_loss: 227.0886\n",
            "Epoch 584/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 339.1650 - val_loss: 223.4459\n",
            "Epoch 585/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 336.0808 - val_loss: 225.1327\n",
            "Epoch 586/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 333.8243 - val_loss: 219.2413\n",
            "Epoch 587/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 330.8991 - val_loss: 216.6138\n",
            "Epoch 588/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 325.9509 - val_loss: 214.0554\n",
            "Epoch 589/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 323.3730 - val_loss: 211.9612\n",
            "Epoch 590/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 319.6905 - val_loss: 209.0330\n",
            "Epoch 591/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 316.8568 - val_loss: 208.1593\n",
            "Epoch 592/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 313.7209 - val_loss: 204.2379\n",
            "Epoch 593/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 310.9511 - val_loss: 202.1753\n",
            "Epoch 594/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 307.6798 - val_loss: 200.5761\n",
            "Epoch 595/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 304.7743 - val_loss: 199.9428\n",
            "Epoch 596/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 303.5722 - val_loss: 197.9140\n",
            "Epoch 597/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 299.8637 - val_loss: 196.5993\n",
            "Epoch 598/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 297.4246 - val_loss: 191.2081\n",
            "Epoch 599/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 294.0266 - val_loss: 190.1892\n",
            "Epoch 600/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 290.6447 - val_loss: 187.9425\n",
            "Epoch 601/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 287.4551 - val_loss: 186.5903\n",
            "Epoch 602/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 285.0629 - val_loss: 183.6310\n",
            "Epoch 603/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 283.5772 - val_loss: 181.3425\n",
            "Epoch 604/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 279.7396 - val_loss: 180.2784\n",
            "Epoch 605/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 277.1181 - val_loss: 177.3450\n",
            "Epoch 606/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 274.7265 - val_loss: 175.3329\n",
            "Epoch 607/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 272.1352 - val_loss: 175.2237\n",
            "Epoch 608/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 271.4463 - val_loss: 175.8593\n",
            "Epoch 609/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 269.1214 - val_loss: 172.6644\n",
            "Epoch 610/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 264.9729 - val_loss: 171.3649\n",
            "Epoch 611/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 261.3411 - val_loss: 167.0034\n",
            "Epoch 612/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 259.2758 - val_loss: 165.6841\n",
            "Epoch 613/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 256.2600 - val_loss: 164.4984\n",
            "Epoch 614/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 253.9063 - val_loss: 161.2444\n",
            "Epoch 615/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 250.7952 - val_loss: 159.0447\n",
            "Epoch 616/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 248.6823 - val_loss: 159.7139\n",
            "Epoch 617/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 248.6916 - val_loss: 155.6007\n",
            "Epoch 618/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 243.9551 - val_loss: 155.0121\n",
            "Epoch 619/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 243.0326 - val_loss: 153.4020\n",
            "Epoch 620/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 239.9853 - val_loss: 152.4096\n",
            "Epoch 621/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 237.0554 - val_loss: 148.8773\n",
            "Epoch 622/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 233.6964 - val_loss: 147.3429\n",
            "Epoch 623/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 232.1516 - val_loss: 147.2716\n",
            "Epoch 624/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 230.7785 - val_loss: 146.3922\n",
            "Epoch 625/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 227.4249 - val_loss: 142.9232\n",
            "Epoch 626/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 225.4409 - val_loss: 141.3849\n",
            "Epoch 627/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 222.6143 - val_loss: 141.3265\n",
            "Epoch 628/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 220.4547 - val_loss: 138.7814\n",
            "Epoch 629/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 218.2881 - val_loss: 137.7671\n",
            "Epoch 630/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 217.3759 - val_loss: 137.8356\n",
            "Epoch 631/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 214.6641 - val_loss: 133.4317\n",
            "Epoch 632/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 213.5063 - val_loss: 133.7502\n",
            "Epoch 633/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 211.5525 - val_loss: 138.6512\n",
            "Epoch 634/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 209.7081 - val_loss: 131.1705\n",
            "Epoch 635/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 206.6184 - val_loss: 128.5544\n",
            "Epoch 636/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 204.4291 - val_loss: 126.6003\n",
            "Epoch 637/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 202.3664 - val_loss: 125.8052\n",
            "Epoch 638/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 200.6627 - val_loss: 128.9849\n",
            "Epoch 639/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 200.0703 - val_loss: 123.6594\n",
            "Epoch 640/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 196.7380 - val_loss: 122.5007\n",
            "Epoch 641/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 193.3323 - val_loss: 120.6280\n",
            "Epoch 642/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 192.0623 - val_loss: 124.2997\n",
            "Epoch 643/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 191.5284 - val_loss: 119.1016\n",
            "Epoch 644/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 187.9092 - val_loss: 117.1582\n",
            "Epoch 645/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 186.3297 - val_loss: 115.4854\n",
            "Epoch 646/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 184.7959 - val_loss: 115.0192\n",
            "Epoch 647/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 183.4279 - val_loss: 112.4011\n",
            "Epoch 648/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 180.2297 - val_loss: 111.0884\n",
            "Epoch 649/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 179.2076 - val_loss: 114.5880\n",
            "Epoch 650/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 177.9349 - val_loss: 110.0065\n",
            "Epoch 651/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 175.4033 - val_loss: 108.6741\n",
            "Epoch 652/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 173.1751 - val_loss: 107.4470\n",
            "Epoch 653/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 172.0896 - val_loss: 105.9164\n",
            "Epoch 654/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 171.1178 - val_loss: 105.8561\n",
            "Epoch 655/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 171.1319 - val_loss: 107.7044\n",
            "Epoch 656/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 167.4075 - val_loss: 104.8037\n",
            "Epoch 657/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 164.8939 - val_loss: 101.9713\n",
            "Epoch 658/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 162.7022 - val_loss: 100.5964\n",
            "Epoch 659/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 161.9678 - val_loss: 100.1184\n",
            "Epoch 660/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 160.4534 - val_loss: 101.0719\n",
            "Epoch 661/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 160.5430 - val_loss: 98.2168\n",
            "Epoch 662/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 158.3635 - val_loss: 99.6261\n",
            "Epoch 663/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 156.0145 - val_loss: 96.2264\n",
            "Epoch 664/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 155.7085 - val_loss: 100.5943\n",
            "Epoch 665/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 153.9168 - val_loss: 93.6373\n",
            "Epoch 666/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 151.5587 - val_loss: 94.2988\n",
            "Epoch 667/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 150.4774 - val_loss: 100.1831\n",
            "Epoch 668/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 149.2584 - val_loss: 92.4536\n",
            "Epoch 669/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 146.0234 - val_loss: 89.6946\n",
            "Epoch 670/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 145.7213 - val_loss: 91.2061\n",
            "Epoch 671/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 144.4392 - val_loss: 90.5151\n",
            "Epoch 672/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 142.3019 - val_loss: 86.9232\n",
            "Epoch 673/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 141.1976 - val_loss: 93.1672\n",
            "Epoch 674/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 140.5111 - val_loss: 92.9218\n",
            "Epoch 675/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 141.6031 - val_loss: 88.6125\n",
            "Epoch 676/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 138.6983 - val_loss: 91.2399\n",
            "Epoch 677/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 137.7952 - val_loss: 92.0265\n",
            "Epoch 678/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 140.1837 - val_loss: 85.6767\n",
            "Epoch 679/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 134.7775 - val_loss: 84.6935\n",
            "Epoch 680/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 131.8203 - val_loss: 80.9373\n",
            "Epoch 681/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 130.5920 - val_loss: 79.2108\n",
            "Epoch 682/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 129.6118 - val_loss: 78.4800\n",
            "Epoch 683/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 127.9246 - val_loss: 78.1437\n",
            "Epoch 684/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 127.0931 - val_loss: 76.6801\n",
            "Epoch 685/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 125.6596 - val_loss: 76.2407\n",
            "Epoch 686/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 123.6912 - val_loss: 74.9804\n",
            "Epoch 687/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 122.6813 - val_loss: 76.8754\n",
            "Epoch 688/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 121.9192 - val_loss: 73.2483\n",
            "Epoch 689/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 121.0028 - val_loss: 76.7257\n",
            "Epoch 690/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 119.6079 - val_loss: 73.8102\n",
            "Epoch 691/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 118.5169 - val_loss: 71.5981\n",
            "Epoch 692/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 118.5469 - val_loss: 77.5224\n",
            "Epoch 693/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 117.3175 - val_loss: 71.9030\n",
            "Epoch 694/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 114.8674 - val_loss: 70.8050\n",
            "Epoch 695/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 113.7016 - val_loss: 68.9438\n",
            "Epoch 696/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 112.9203 - val_loss: 68.7468\n",
            "Epoch 697/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 112.3173 - val_loss: 67.0695\n",
            "Epoch 698/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 111.3106 - val_loss: 66.7402\n",
            "Epoch 699/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 109.1043 - val_loss: 65.7139\n",
            "Epoch 700/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 108.2402 - val_loss: 67.7365\n",
            "Epoch 701/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 108.5173 - val_loss: 64.1944\n",
            "Epoch 702/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 106.4217 - val_loss: 66.6963\n",
            "Epoch 703/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 105.3445 - val_loss: 69.1000\n",
            "Epoch 704/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 106.2963 - val_loss: 64.7618\n",
            "Epoch 705/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 103.8926 - val_loss: 64.3104\n",
            "Epoch 706/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 101.6956 - val_loss: 62.4118\n",
            "Epoch 707/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 100.6120 - val_loss: 61.3106\n",
            "Epoch 708/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 100.0517 - val_loss: 60.6457\n",
            "Epoch 709/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 99.3755 - val_loss: 60.7873\n",
            "Epoch 710/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 98.3180 - val_loss: 59.2523\n",
            "Epoch 711/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 96.9156 - val_loss: 60.5873\n",
            "Epoch 712/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 96.0473 - val_loss: 58.9980\n",
            "Epoch 713/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 96.4606 - val_loss: 58.3888\n",
            "Epoch 714/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 97.0364 - val_loss: 61.5268\n",
            "Epoch 715/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 96.5212 - val_loss: 68.6551\n",
            "Epoch 716/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 94.8135 - val_loss: 57.2668\n",
            "Epoch 717/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 93.7053 - val_loss: 58.0823\n",
            "Epoch 718/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 93.0616 - val_loss: 60.1225\n",
            "Epoch 719/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 91.0761 - val_loss: 55.1079\n",
            "Epoch 720/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 89.4855 - val_loss: 54.2303\n",
            "Epoch 721/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 89.6460 - val_loss: 57.5683\n",
            "Epoch 722/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 88.0173 - val_loss: 54.1234\n",
            "Epoch 723/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 87.5082 - val_loss: 54.0906\n",
            "Epoch 724/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 87.0427 - val_loss: 55.8395\n",
            "Epoch 725/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 85.9239 - val_loss: 55.8753\n",
            "Epoch 726/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 84.6604 - val_loss: 50.5441\n",
            "Epoch 727/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 83.7627 - val_loss: 52.0169\n",
            "Epoch 728/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 83.8034 - val_loss: 49.1256\n",
            "Epoch 729/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 84.4051 - val_loss: 48.8529\n",
            "Epoch 730/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 81.5087 - val_loss: 49.0719\n",
            "Epoch 731/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 81.0269 - val_loss: 48.0919\n",
            "Epoch 732/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 81.3424 - val_loss: 50.2088\n",
            "Epoch 733/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 80.1682 - val_loss: 48.3580\n",
            "Epoch 734/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 78.8786 - val_loss: 48.6407\n",
            "Epoch 735/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 77.9210 - val_loss: 46.6675\n",
            "Epoch 736/1500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 77.7714 - val_loss: 45.8659\n",
            "Epoch 737/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 76.7227 - val_loss: 46.8995\n",
            "Epoch 738/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 77.5673 - val_loss: 47.0579\n",
            "Epoch 739/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 75.1242 - val_loss: 44.6411\n",
            "Epoch 740/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 74.0392 - val_loss: 44.0362\n",
            "Epoch 741/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 73.7170 - val_loss: 44.1742\n",
            "Epoch 742/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 73.2063 - val_loss: 46.0393\n",
            "Epoch 743/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 73.0458 - val_loss: 43.8866\n",
            "Epoch 744/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 73.1026 - val_loss: 48.8036\n",
            "Epoch 745/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 75.1212 - val_loss: 46.1919\n",
            "Epoch 746/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 73.2473 - val_loss: 42.6293\n",
            "Epoch 747/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 70.9469 - val_loss: 42.0980\n",
            "Epoch 748/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 70.2860 - val_loss: 41.1326\n",
            "Epoch 749/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 67.9091 - val_loss: 42.1544\n",
            "Epoch 750/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 67.9920 - val_loss: 45.3486\n",
            "Epoch 751/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 71.4641 - val_loss: 41.5458\n",
            "Epoch 752/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 68.2814 - val_loss: 43.6229\n",
            "Epoch 753/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 66.4665 - val_loss: 39.2213\n",
            "Epoch 754/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 65.1895 - val_loss: 40.8466\n",
            "Epoch 755/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 64.9970 - val_loss: 39.4455\n",
            "Epoch 756/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 64.3880 - val_loss: 38.7473\n",
            "Epoch 757/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 64.2557 - val_loss: 38.3349\n",
            "Epoch 758/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 64.3833 - val_loss: 38.3990\n",
            "Epoch 759/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 63.4107 - val_loss: 38.0079\n",
            "Epoch 760/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 61.6821 - val_loss: 37.3578\n",
            "Epoch 761/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 62.0803 - val_loss: 37.7054\n",
            "Epoch 762/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 61.2359 - val_loss: 37.2864\n",
            "Epoch 763/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 61.3288 - val_loss: 38.5753\n",
            "Epoch 764/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 61.9686 - val_loss: 37.2171\n",
            "Epoch 765/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 60.9579 - val_loss: 37.6274\n",
            "Epoch 766/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 59.5075 - val_loss: 36.2063\n",
            "Epoch 767/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 59.3788 - val_loss: 38.0330\n",
            "Epoch 768/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 57.6478 - val_loss: 35.3819\n",
            "Epoch 769/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 56.2959 - val_loss: 38.4946\n",
            "Epoch 770/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 58.2784 - val_loss: 37.6069\n",
            "Epoch 771/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 61.0083 - val_loss: 36.6768\n",
            "Epoch 772/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 56.7459 - val_loss: 33.9642\n",
            "Epoch 773/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 55.6831 - val_loss: 34.5333\n",
            "Epoch 774/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 56.3762 - val_loss: 37.1984\n",
            "Epoch 775/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 55.1037 - val_loss: 34.8720\n",
            "Epoch 776/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 55.6955 - val_loss: 33.1240\n",
            "Epoch 777/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 55.2981 - val_loss: 33.5936\n",
            "Epoch 778/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 53.0315 - val_loss: 34.6619\n",
            "Epoch 779/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 54.6752 - val_loss: 35.4472\n",
            "Epoch 780/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 52.6823 - val_loss: 32.5472\n",
            "Epoch 781/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 51.6084 - val_loss: 32.2819\n",
            "Epoch 782/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 53.9693 - val_loss: 31.8892\n",
            "Epoch 783/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 52.3998 - val_loss: 32.1180\n",
            "Epoch 784/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 52.5051 - val_loss: 33.5476\n",
            "Epoch 785/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 51.6404 - val_loss: 32.7064\n",
            "Epoch 786/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 51.4416 - val_loss: 33.0121\n",
            "Epoch 787/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 52.1197 - val_loss: 34.7637\n",
            "Epoch 788/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 55.3013 - val_loss: 32.0599\n",
            "Epoch 789/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 50.8706 - val_loss: 31.6218\n",
            "Epoch 790/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 48.7183 - val_loss: 30.8791\n",
            "Epoch 791/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 49.2025 - val_loss: 33.2391\n",
            "Epoch 792/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 49.1069 - val_loss: 30.1064\n",
            "Epoch 793/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 49.5122 - val_loss: 33.6077\n",
            "Epoch 794/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 53.2886 - val_loss: 33.0784\n",
            "Epoch 795/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 50.2502 - val_loss: 34.5730\n",
            "Epoch 796/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 51.5144 - val_loss: 30.3605\n",
            "Epoch 797/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 47.0377 - val_loss: 37.8802\n",
            "Epoch 798/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 49.1436 - val_loss: 30.8739\n",
            "Epoch 799/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 47.7480 - val_loss: 29.5918\n",
            "Epoch 800/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 48.0841 - val_loss: 28.9397\n",
            "Epoch 801/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 46.1079 - val_loss: 29.7418\n",
            "Epoch 802/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 45.9915 - val_loss: 28.9547\n",
            "Epoch 803/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 44.9710 - val_loss: 27.9858\n",
            "Epoch 804/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 47.0926 - val_loss: 27.2210\n",
            "Epoch 805/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 44.9606 - val_loss: 27.3099\n",
            "Epoch 806/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 44.8262 - val_loss: 26.8753\n",
            "Epoch 807/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 44.4949 - val_loss: 30.2209\n",
            "Epoch 808/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 44.0211 - val_loss: 27.3718\n",
            "Epoch 809/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 44.9077 - val_loss: 26.8862\n",
            "Epoch 810/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 44.5314 - val_loss: 28.3648\n",
            "Epoch 811/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 45.0113 - val_loss: 28.8184\n",
            "Epoch 812/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 43.5943 - val_loss: 26.3628\n",
            "Epoch 813/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 43.1096 - val_loss: 26.6122\n",
            "Epoch 814/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 42.5498 - val_loss: 25.2637\n",
            "Epoch 815/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 42.9171 - val_loss: 26.4899\n",
            "Epoch 816/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 42.7446 - val_loss: 29.6717\n",
            "Epoch 817/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 43.0057 - val_loss: 28.0897\n",
            "Epoch 818/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 43.3922 - val_loss: 28.1687\n",
            "Epoch 819/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 46.3742 - val_loss: 32.1777\n",
            "Epoch 820/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 45.5523 - val_loss: 28.6037\n",
            "Epoch 821/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 44.8226 - val_loss: 26.2810\n",
            "Epoch 822/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 42.5041 - val_loss: 26.7026\n",
            "Epoch 823/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 42.6413 - val_loss: 25.7867\n",
            "Epoch 824/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 42.1832 - val_loss: 25.1097\n",
            "Epoch 825/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 40.3950 - val_loss: 24.3479\n",
            "Epoch 826/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 40.8754 - val_loss: 29.9170\n",
            "Epoch 827/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 41.0854 - val_loss: 25.0905\n",
            "Epoch 828/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 40.0641 - val_loss: 26.2449\n",
            "Epoch 829/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 39.6815 - val_loss: 25.5768\n",
            "Epoch 830/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 39.1285 - val_loss: 25.0022\n",
            "Epoch 831/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 39.8736 - val_loss: 24.5387\n",
            "Epoch 832/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 40.1951 - val_loss: 28.5278\n",
            "Epoch 833/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 40.4298 - val_loss: 24.5129\n",
            "Epoch 834/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 40.0591 - val_loss: 24.2377\n",
            "Epoch 835/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 41.4379 - val_loss: 24.2090\n",
            "Epoch 836/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 38.6965 - val_loss: 25.3460\n",
            "Epoch 837/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 38.1700 - val_loss: 28.3246\n",
            "Epoch 838/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 40.0345 - val_loss: 27.3042\n",
            "Epoch 839/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 41.2238 - val_loss: 28.9990\n",
            "Epoch 840/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 42.3128 - val_loss: 29.7370\n",
            "Epoch 841/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 38.6074 - val_loss: 24.3821\n",
            "Epoch 842/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 38.3107 - val_loss: 23.7217\n",
            "Epoch 843/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 37.7529 - val_loss: 24.9887\n",
            "Epoch 844/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 36.7885 - val_loss: 25.7346\n",
            "Epoch 845/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 36.6328 - val_loss: 25.9061\n",
            "Epoch 846/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 38.1523 - val_loss: 23.5350\n",
            "Epoch 847/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 38.7237 - val_loss: 24.5225\n",
            "Epoch 848/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 37.0274 - val_loss: 24.5989\n",
            "Epoch 849/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 36.2145 - val_loss: 22.8857\n",
            "Epoch 850/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 35.5306 - val_loss: 22.9680\n",
            "Epoch 851/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 39.2400 - val_loss: 30.7048\n",
            "Epoch 852/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 37.3201 - val_loss: 28.7654\n",
            "Epoch 853/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 36.1602 - val_loss: 23.0671\n",
            "Epoch 854/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 34.7643 - val_loss: 23.6674\n",
            "Epoch 855/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 35.7648 - val_loss: 24.3964\n",
            "Epoch 856/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 34.3087 - val_loss: 22.4191\n",
            "Epoch 857/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 34.8736 - val_loss: 25.5784\n",
            "Epoch 858/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 36.7322 - val_loss: 25.0605\n",
            "Epoch 859/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 34.1682 - val_loss: 22.9906\n",
            "Epoch 860/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 34.4976 - val_loss: 22.5767\n",
            "Epoch 861/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 33.8942 - val_loss: 22.7161\n",
            "Epoch 862/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 33.0647 - val_loss: 24.7344\n",
            "Epoch 863/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 33.2857 - val_loss: 22.4744\n",
            "Epoch 864/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 33.2000 - val_loss: 23.9371\n",
            "Epoch 865/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 35.1722 - val_loss: 22.4993\n",
            "Epoch 866/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 34.0049 - val_loss: 26.1889\n",
            "Epoch 867/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 33.2628 - val_loss: 21.8983\n",
            "Epoch 868/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 33.4415 - val_loss: 22.7798\n",
            "Epoch 869/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 33.1817 - val_loss: 24.2563\n",
            "Epoch 870/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 33.2827 - val_loss: 22.1150\n",
            "Epoch 871/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 32.8800 - val_loss: 27.6443\n",
            "Epoch 872/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 33.7325 - val_loss: 26.0343\n",
            "Epoch 873/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 32.6656 - val_loss: 21.2379\n",
            "Epoch 874/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 31.7393 - val_loss: 23.3182\n",
            "Epoch 875/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 31.2718 - val_loss: 23.0881\n",
            "Epoch 876/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 32.0195 - val_loss: 23.5244\n",
            "Epoch 877/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 32.4760 - val_loss: 22.5700\n",
            "Epoch 878/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 31.2348 - val_loss: 21.4330\n",
            "Epoch 879/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 31.2793 - val_loss: 22.9359\n",
            "Epoch 880/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 31.0444 - val_loss: 20.4284\n",
            "Epoch 881/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 30.8838 - val_loss: 21.7038\n",
            "Epoch 882/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 30.3986 - val_loss: 22.7876\n",
            "Epoch 883/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 30.5265 - val_loss: 21.3621\n",
            "Epoch 884/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 31.2419 - val_loss: 22.2251\n",
            "Epoch 885/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 31.2262 - val_loss: 24.5692\n",
            "Epoch 886/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 30.8487 - val_loss: 22.7898\n",
            "Epoch 887/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 31.1097 - val_loss: 22.2467\n",
            "Epoch 888/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 30.4459 - val_loss: 23.9385\n",
            "Epoch 889/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 29.8395 - val_loss: 20.2479\n",
            "Epoch 890/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 29.6006 - val_loss: 21.6259\n",
            "Epoch 891/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 30.2472 - val_loss: 20.6937\n",
            "Epoch 892/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 29.6816 - val_loss: 19.5469\n",
            "Epoch 893/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 29.3456 - val_loss: 28.3132\n",
            "Epoch 894/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 31.1513 - val_loss: 19.7174\n",
            "Epoch 895/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 31.4712 - val_loss: 20.4083\n",
            "Epoch 896/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 29.8740 - val_loss: 20.3507\n",
            "Epoch 897/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 29.2750 - val_loss: 19.0424\n",
            "Epoch 898/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 27.8629 - val_loss: 22.2186\n",
            "Epoch 899/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 29.5116 - val_loss: 19.7587\n",
            "Epoch 900/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 28.6396 - val_loss: 20.3844\n",
            "Epoch 901/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 28.2693 - val_loss: 20.3752\n",
            "Epoch 902/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 28.9013 - val_loss: 20.3418\n",
            "Epoch 903/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 27.5643 - val_loss: 21.1165\n",
            "Epoch 904/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 28.2613 - val_loss: 19.7313\n",
            "Epoch 905/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 28.0455 - val_loss: 18.8621\n",
            "Epoch 906/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 27.1744 - val_loss: 20.2205\n",
            "Epoch 907/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 27.3036 - val_loss: 19.3857\n",
            "Epoch 908/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 27.0613 - val_loss: 22.1050\n",
            "Epoch 909/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 27.6894 - val_loss: 21.4730\n",
            "Epoch 910/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 27.0710 - val_loss: 20.2964\n",
            "Epoch 911/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 26.5722 - val_loss: 21.3359\n",
            "Epoch 912/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 27.0047 - val_loss: 20.7430\n",
            "Epoch 913/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 26.7176 - val_loss: 19.3215\n",
            "Epoch 914/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 26.8013 - val_loss: 19.6771\n",
            "Epoch 915/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 28.1675 - val_loss: 23.5031\n",
            "Epoch 916/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 28.3261 - val_loss: 19.7017\n",
            "Epoch 917/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 26.6580 - val_loss: 18.4993\n",
            "Epoch 918/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 27.2824 - val_loss: 19.6989\n",
            "Epoch 919/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 26.3821 - val_loss: 17.5159\n",
            "Epoch 920/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 25.4182 - val_loss: 18.7629\n",
            "Epoch 921/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 25.4564 - val_loss: 19.4910\n",
            "Epoch 922/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 26.6716 - val_loss: 20.2750\n",
            "Epoch 923/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 26.7505 - val_loss: 21.1167\n",
            "Epoch 924/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 26.9315 - val_loss: 18.0731\n",
            "Epoch 925/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 25.6626 - val_loss: 17.8419\n",
            "Epoch 926/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 25.5365 - val_loss: 18.2728\n",
            "Epoch 927/1500\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 25.1888 - val_loss: 19.2488\n",
            "Epoch 928/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 24.7852 - val_loss: 17.9856\n",
            "Epoch 929/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 24.1903 - val_loss: 17.5303\n",
            "Epoch 930/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 24.3768 - val_loss: 18.2964\n",
            "Epoch 931/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 24.3763 - val_loss: 17.3298\n",
            "Epoch 932/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 24.4284 - val_loss: 18.2432\n",
            "Epoch 933/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 24.6948 - val_loss: 22.2086\n",
            "Epoch 934/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 25.2593 - val_loss: 21.0745\n",
            "Epoch 935/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 24.6108 - val_loss: 21.4897\n",
            "Epoch 936/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 26.0595 - val_loss: 17.2636\n",
            "Epoch 937/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 23.6641 - val_loss: 19.0052\n",
            "Epoch 938/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 24.1753 - val_loss: 17.4915\n",
            "Epoch 939/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 23.3222 - val_loss: 16.7420\n",
            "Epoch 940/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 23.9187 - val_loss: 17.7653\n",
            "Epoch 941/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 23.2981 - val_loss: 17.8877\n",
            "Epoch 942/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 23.2840 - val_loss: 18.7946\n",
            "Epoch 943/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 23.6243 - val_loss: 16.6380\n",
            "Epoch 944/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 24.2501 - val_loss: 17.6978\n",
            "Epoch 945/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 23.8420 - val_loss: 17.0229\n",
            "Epoch 946/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 23.1460 - val_loss: 18.1573\n",
            "Epoch 947/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 24.0885 - val_loss: 17.3114\n",
            "Epoch 948/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 24.2955 - val_loss: 16.7376\n",
            "Epoch 949/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 24.6052 - val_loss: 19.3148\n",
            "Epoch 950/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 24.2087 - val_loss: 21.5844\n",
            "Epoch 951/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 24.6840 - val_loss: 17.0686\n",
            "Epoch 952/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 22.6752 - val_loss: 16.4960\n",
            "Epoch 953/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 23.1801 - val_loss: 18.7092\n",
            "Epoch 954/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 23.4905 - val_loss: 16.7983\n",
            "Epoch 955/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 23.4632 - val_loss: 16.2150\n",
            "Epoch 956/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 23.1526 - val_loss: 18.5229\n",
            "Epoch 957/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 23.3487 - val_loss: 17.4659\n",
            "Epoch 958/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 24.5316 - val_loss: 19.3405\n",
            "Epoch 959/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 24.0002 - val_loss: 16.5180\n",
            "Epoch 960/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 22.1289 - val_loss: 16.6247\n",
            "Epoch 961/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 22.3369 - val_loss: 16.3343\n",
            "Epoch 962/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 24.0528 - val_loss: 17.0397\n",
            "Epoch 963/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 24.2469 - val_loss: 19.9887\n",
            "Epoch 964/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 23.1110 - val_loss: 16.0581\n",
            "Epoch 965/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 23.6430 - val_loss: 16.4333\n",
            "Epoch 966/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 21.8382 - val_loss: 16.3940\n",
            "Epoch 967/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 21.6272 - val_loss: 17.3190\n",
            "Epoch 968/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 22.8801 - val_loss: 18.1599\n",
            "Epoch 969/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 21.8888 - val_loss: 17.2065\n",
            "Epoch 970/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 21.9791 - val_loss: 17.5530\n",
            "Epoch 971/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 24.2114 - val_loss: 23.7903\n",
            "Epoch 972/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 30.9053 - val_loss: 17.6777\n",
            "Epoch 973/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 24.7553 - val_loss: 17.0783\n",
            "Epoch 974/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 21.5007 - val_loss: 16.7858\n",
            "Epoch 975/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 22.6711 - val_loss: 18.9168\n",
            "Epoch 976/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 22.4512 - val_loss: 16.4019\n",
            "Epoch 977/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 21.4556 - val_loss: 16.0094\n",
            "Epoch 978/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 20.7883 - val_loss: 16.0510\n",
            "Epoch 979/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 22.2192 - val_loss: 15.5996\n",
            "Epoch 980/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 20.5794 - val_loss: 15.4421\n",
            "Epoch 981/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 20.8802 - val_loss: 20.3832\n",
            "Epoch 982/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 23.0001 - val_loss: 16.6233\n",
            "Epoch 983/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 21.3492 - val_loss: 16.9176\n",
            "Epoch 984/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 21.6468 - val_loss: 15.7779\n",
            "Epoch 985/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 20.9901 - val_loss: 15.6884\n",
            "Epoch 986/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 20.3372 - val_loss: 16.6200\n",
            "Epoch 987/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 21.0383 - val_loss: 17.3822\n",
            "Epoch 988/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 24.4544 - val_loss: 16.5363\n",
            "Epoch 989/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 22.0034 - val_loss: 19.5317\n",
            "Epoch 990/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 21.6958 - val_loss: 15.5519\n",
            "Epoch 991/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 20.2613 - val_loss: 15.7691\n",
            "Epoch 992/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 20.2710 - val_loss: 15.6651\n",
            "Epoch 993/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 19.8749 - val_loss: 16.0007\n",
            "Epoch 994/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 19.5502 - val_loss: 14.9328\n",
            "Epoch 995/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 19.2117 - val_loss: 18.7272\n",
            "Epoch 996/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 21.6727 - val_loss: 16.7146\n",
            "Epoch 997/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 20.2315 - val_loss: 16.8813\n",
            "Epoch 998/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 21.9631 - val_loss: 16.9434\n",
            "Epoch 999/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 21.6705 - val_loss: 16.0606\n",
            "Epoch 1000/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 20.1141 - val_loss: 18.0482\n",
            "Epoch 1001/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 20.1400 - val_loss: 15.8308\n",
            "Epoch 1002/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 19.9340 - val_loss: 16.5750\n",
            "Epoch 1003/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 20.6068 - val_loss: 15.2259\n",
            "Epoch 1004/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 19.9246 - val_loss: 15.0540\n",
            "Epoch 1005/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 19.6924 - val_loss: 15.1049\n",
            "Epoch 1006/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 20.8601 - val_loss: 15.5707\n",
            "Epoch 1007/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 20.9137 - val_loss: 19.4130\n",
            "Epoch 1008/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 20.2649 - val_loss: 16.5184\n",
            "Epoch 1009/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 20.6022 - val_loss: 18.2693\n",
            "Epoch 1010/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 20.9638 - val_loss: 16.7068\n",
            "Epoch 1011/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 21.4031 - val_loss: 16.1978\n",
            "Epoch 1012/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 20.6294 - val_loss: 15.6144\n",
            "Epoch 1013/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 22.0344 - val_loss: 15.8358\n",
            "Epoch 1014/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 21.8594 - val_loss: 19.4382\n",
            "Epoch 1015/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 20.5252 - val_loss: 17.7614\n",
            "Epoch 1016/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 20.3419 - val_loss: 15.6738\n",
            "Epoch 1017/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 19.6074 - val_loss: 16.4712\n",
            "Epoch 1018/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 19.7213 - val_loss: 14.6279\n",
            "Epoch 1019/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 20.2244 - val_loss: 16.8617\n",
            "Epoch 1020/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 19.3167 - val_loss: 15.7014\n",
            "Epoch 1021/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 19.6580 - val_loss: 15.5788\n",
            "Epoch 1022/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 19.9618 - val_loss: 15.2311\n",
            "Epoch 1023/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 19.1436 - val_loss: 14.2916\n",
            "Epoch 1024/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 18.8092 - val_loss: 14.5278\n",
            "Epoch 1025/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 19.2514 - val_loss: 16.1965\n",
            "Epoch 1026/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 19.6203 - val_loss: 18.3281\n",
            "Epoch 1027/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 19.6563 - val_loss: 15.5622\n",
            "Epoch 1028/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 22.2860 - val_loss: 25.3891\n",
            "Epoch 1029/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 24.4937 - val_loss: 16.2460\n",
            "Epoch 1030/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 20.2300 - val_loss: 17.5214\n",
            "Epoch 1031/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 28.0813 - val_loss: 19.0768\n",
            "Epoch 1032/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 21.6088 - val_loss: 15.3684\n",
            "Epoch 1033/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 19.1927 - val_loss: 15.2446\n",
            "Epoch 1034/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 19.4029 - val_loss: 15.4993\n",
            "Epoch 1035/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 19.2399 - val_loss: 17.6610\n",
            "Epoch 1036/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 19.3265 - val_loss: 15.4865\n",
            "Epoch 1037/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.4698 - val_loss: 15.5510\n",
            "Epoch 1038/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 19.5930 - val_loss: 18.3758\n",
            "Epoch 1039/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 20.2231 - val_loss: 21.6618\n",
            "Epoch 1040/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 20.5187 - val_loss: 17.4787\n",
            "Epoch 1041/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 19.5993 - val_loss: 15.7793\n",
            "Epoch 1042/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 20.3717 - val_loss: 15.9900\n",
            "Epoch 1043/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 20.5404 - val_loss: 18.7251\n",
            "Epoch 1044/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 19.5303 - val_loss: 17.3528\n",
            "Epoch 1045/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 20.8475 - val_loss: 18.5939\n",
            "Epoch 1046/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 21.6907 - val_loss: 15.5578\n",
            "Epoch 1047/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 19.2186 - val_loss: 15.1810\n",
            "Epoch 1048/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 18.6932 - val_loss: 14.6874\n",
            "Epoch 1049/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 17.7958 - val_loss: 14.6144\n",
            "Epoch 1050/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.8923 - val_loss: 18.6171\n",
            "Epoch 1051/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 19.0923 - val_loss: 14.8017\n",
            "Epoch 1052/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.0264 - val_loss: 15.4809\n",
            "Epoch 1053/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 18.7900 - val_loss: 17.4812\n",
            "Epoch 1054/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 19.3586 - val_loss: 16.3129\n",
            "Epoch 1055/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 20.8572 - val_loss: 16.2654\n",
            "Epoch 1056/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 20.9443 - val_loss: 16.6529\n",
            "Epoch 1057/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 19.8517 - val_loss: 14.9604\n",
            "Epoch 1058/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 19.3088 - val_loss: 15.1254\n",
            "Epoch 1059/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 20.1737 - val_loss: 16.2316\n",
            "Epoch 1060/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 21.1375 - val_loss: 16.4138\n",
            "Epoch 1061/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 18.9584 - val_loss: 14.4160\n",
            "Epoch 1062/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 17.6717 - val_loss: 14.2702\n",
            "Epoch 1063/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 18.3549 - val_loss: 14.8245\n",
            "Epoch 1064/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 18.3814 - val_loss: 14.6662\n",
            "Epoch 1065/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.0638 - val_loss: 15.3120\n",
            "Epoch 1066/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 17.3998 - val_loss: 14.4675\n",
            "Epoch 1067/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 17.8535 - val_loss: 14.5250\n",
            "Epoch 1068/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 18.0567 - val_loss: 16.3500\n",
            "Epoch 1069/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 18.8883 - val_loss: 15.3802\n",
            "Epoch 1070/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 20.6215 - val_loss: 22.1145\n",
            "Epoch 1071/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 22.4505 - val_loss: 17.7009\n",
            "Epoch 1072/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 21.2311 - val_loss: 14.0856\n",
            "Epoch 1073/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 19.6299 - val_loss: 19.1109\n",
            "Epoch 1074/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 19.9303 - val_loss: 16.0532\n",
            "Epoch 1075/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 19.0567 - val_loss: 14.7246\n",
            "Epoch 1076/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 18.5047 - val_loss: 14.7566\n",
            "Epoch 1077/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.8107 - val_loss: 14.9202\n",
            "Epoch 1078/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 18.5049 - val_loss: 17.8938\n",
            "Epoch 1079/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.7629 - val_loss: 13.9981\n",
            "Epoch 1080/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.8756 - val_loss: 14.4312\n",
            "Epoch 1081/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.0810 - val_loss: 15.3252\n",
            "Epoch 1082/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 18.4875 - val_loss: 14.5279\n",
            "Epoch 1083/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 18.4349 - val_loss: 15.9052\n",
            "Epoch 1084/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 19.7305 - val_loss: 13.8766\n",
            "Epoch 1085/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 17.8874 - val_loss: 14.3544\n",
            "Epoch 1086/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 17.3144 - val_loss: 14.2120\n",
            "Epoch 1087/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 19.9146 - val_loss: 15.5381\n",
            "Epoch 1088/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 19.2196 - val_loss: 17.3293\n",
            "Epoch 1089/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 19.2615 - val_loss: 14.9321\n",
            "Epoch 1090/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 19.8423 - val_loss: 15.0384\n",
            "Epoch 1091/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 18.8736 - val_loss: 14.1229\n",
            "Epoch 1092/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 18.8984 - val_loss: 14.2573\n",
            "Epoch 1093/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 19.2858 - val_loss: 13.9232\n",
            "Epoch 1094/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.6570 - val_loss: 16.6674\n",
            "Epoch 1095/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 18.4002 - val_loss: 18.2122\n",
            "Epoch 1096/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.7784 - val_loss: 14.3045\n",
            "Epoch 1097/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 18.7687 - val_loss: 14.7978\n",
            "Epoch 1098/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.7820 - val_loss: 13.7484\n",
            "Epoch 1099/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 17.2853 - val_loss: 14.4066\n",
            "Epoch 1100/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.8906 - val_loss: 14.7656\n",
            "Epoch 1101/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 18.9218 - val_loss: 16.1234\n",
            "Epoch 1102/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.8354 - val_loss: 13.8301\n",
            "Epoch 1103/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.1620 - val_loss: 14.3337\n",
            "Epoch 1104/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.0114 - val_loss: 15.0309\n",
            "Epoch 1105/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.6168 - val_loss: 14.5085\n",
            "Epoch 1106/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.7359 - val_loss: 15.1235\n",
            "Epoch 1107/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 18.7240 - val_loss: 15.2592\n",
            "Epoch 1108/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.0180 - val_loss: 14.7396\n",
            "Epoch 1109/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 17.7322 - val_loss: 16.2555\n",
            "Epoch 1110/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 18.2301 - val_loss: 13.7156\n",
            "Epoch 1111/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.5291 - val_loss: 15.8432\n",
            "Epoch 1112/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.6490 - val_loss: 13.8009\n",
            "Epoch 1113/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.0945 - val_loss: 15.4657\n",
            "Epoch 1114/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.4187 - val_loss: 14.9664\n",
            "Epoch 1115/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.7383 - val_loss: 14.8504\n",
            "Epoch 1116/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.5625 - val_loss: 14.2784\n",
            "Epoch 1117/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.2879 - val_loss: 14.1751\n",
            "Epoch 1118/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.5201 - val_loss: 14.1442\n",
            "Epoch 1119/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.3887 - val_loss: 14.2307\n",
            "Epoch 1120/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.6030 - val_loss: 14.2819\n",
            "Epoch 1121/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.3151 - val_loss: 13.8554\n",
            "Epoch 1122/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.7364 - val_loss: 14.7062\n",
            "Epoch 1123/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.8622 - val_loss: 13.4088\n",
            "Epoch 1124/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.6867 - val_loss: 14.4502\n",
            "Epoch 1125/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.9241 - val_loss: 18.8138\n",
            "Epoch 1126/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.4028 - val_loss: 15.5258\n",
            "Epoch 1127/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.3634 - val_loss: 14.2774\n",
            "Epoch 1128/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.8777 - val_loss: 14.2901\n",
            "Epoch 1129/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.2336 - val_loss: 14.6865\n",
            "Epoch 1130/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.1114 - val_loss: 13.8427\n",
            "Epoch 1131/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.8891 - val_loss: 14.6497\n",
            "Epoch 1132/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 19.2096 - val_loss: 16.5662\n",
            "Epoch 1133/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.5115 - val_loss: 14.3351\n",
            "Epoch 1134/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.4160 - val_loss: 15.7138\n",
            "Epoch 1135/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 17.8568 - val_loss: 14.5454\n",
            "Epoch 1136/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.7024 - val_loss: 14.6247\n",
            "Epoch 1137/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 17.3336 - val_loss: 14.0651\n",
            "Epoch 1138/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.8278 - val_loss: 15.6507\n",
            "Epoch 1139/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 20.4969 - val_loss: 15.7684\n",
            "Epoch 1140/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 19.7445 - val_loss: 16.9054\n",
            "Epoch 1141/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 20.7145 - val_loss: 15.6138\n",
            "Epoch 1142/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.8521 - val_loss: 16.5925\n",
            "Epoch 1143/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.9718 - val_loss: 13.6992\n",
            "Epoch 1144/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 17.3485 - val_loss: 14.2715\n",
            "Epoch 1145/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.1761 - val_loss: 14.0615\n",
            "Epoch 1146/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 18.3990 - val_loss: 16.3982\n",
            "Epoch 1147/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.4513 - val_loss: 17.5552\n",
            "Epoch 1148/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 20.1144 - val_loss: 19.7758\n",
            "Epoch 1149/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 18.1210 - val_loss: 14.9631\n",
            "Epoch 1150/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.3372 - val_loss: 17.4891\n",
            "Epoch 1151/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 20.2183 - val_loss: 13.6672\n",
            "Epoch 1152/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 16.9170 - val_loss: 14.4884\n",
            "Epoch 1153/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.3284 - val_loss: 13.7053\n",
            "Epoch 1154/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.1308 - val_loss: 15.6634\n",
            "Epoch 1155/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 17.8042 - val_loss: 15.5442\n",
            "Epoch 1156/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 17.4847 - val_loss: 14.5262\n",
            "Epoch 1157/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.8830 - val_loss: 15.3513\n",
            "Epoch 1158/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.1912 - val_loss: 16.5336\n",
            "Epoch 1159/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 18.5053 - val_loss: 14.0023\n",
            "Epoch 1160/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.1083 - val_loss: 14.5897\n",
            "Epoch 1161/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.6173 - val_loss: 13.4900\n",
            "Epoch 1162/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.9128 - val_loss: 16.3140\n",
            "Epoch 1163/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 18.0355 - val_loss: 15.4480\n",
            "Epoch 1164/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 18.6232 - val_loss: 13.9392\n",
            "Epoch 1165/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 17.7151 - val_loss: 18.1125\n",
            "Epoch 1166/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.0066 - val_loss: 17.4322\n",
            "Epoch 1167/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.0287 - val_loss: 14.0196\n",
            "Epoch 1168/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.5538 - val_loss: 14.1067\n",
            "Epoch 1169/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 19.7795 - val_loss: 17.5819\n",
            "Epoch 1170/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 19.5752 - val_loss: 14.7531\n",
            "Epoch 1171/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.8064 - val_loss: 13.7824\n",
            "Epoch 1172/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.3599 - val_loss: 15.1705\n",
            "Epoch 1173/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.7797 - val_loss: 15.8009\n",
            "Epoch 1174/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.6025 - val_loss: 14.7817\n",
            "Epoch 1175/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.9334 - val_loss: 20.2064\n",
            "Epoch 1176/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 19.3623 - val_loss: 17.3993\n",
            "Epoch 1177/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.9859 - val_loss: 14.1538\n",
            "Epoch 1178/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.3928 - val_loss: 14.4058\n",
            "Epoch 1179/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.3027 - val_loss: 13.4189\n",
            "Epoch 1180/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 17.1775 - val_loss: 13.9433\n",
            "Epoch 1181/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.5330 - val_loss: 14.0430\n",
            "Epoch 1182/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.7348 - val_loss: 14.0563\n",
            "Epoch 1183/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.6950 - val_loss: 15.5366\n",
            "Epoch 1184/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.4519 - val_loss: 13.9100\n",
            "Epoch 1185/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.9817 - val_loss: 13.9216\n",
            "Epoch 1186/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.9406 - val_loss: 15.8397\n",
            "Epoch 1187/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.5940 - val_loss: 14.8094\n",
            "Epoch 1188/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.3071 - val_loss: 14.8678\n",
            "Epoch 1189/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.8148 - val_loss: 15.9303\n",
            "Epoch 1190/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.6515 - val_loss: 13.7451\n",
            "Epoch 1191/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.3137 - val_loss: 14.7994\n",
            "Epoch 1192/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.4828 - val_loss: 16.5312\n",
            "Epoch 1193/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.8612 - val_loss: 16.7640\n",
            "Epoch 1194/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 18.8423 - val_loss: 15.0952\n",
            "Epoch 1195/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 18.4348 - val_loss: 13.6972\n",
            "Epoch 1196/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.5595 - val_loss: 13.2232\n",
            "Epoch 1197/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.7828 - val_loss: 15.5868\n",
            "Epoch 1198/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.3739 - val_loss: 17.8141\n",
            "Epoch 1199/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.4542 - val_loss: 15.3088\n",
            "Epoch 1200/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.8181 - val_loss: 14.5192\n",
            "Epoch 1201/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.7261 - val_loss: 14.0122\n",
            "Epoch 1202/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 16.1614 - val_loss: 14.0794\n",
            "Epoch 1203/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.7860 - val_loss: 13.6102\n",
            "Epoch 1204/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.6374 - val_loss: 17.3011\n",
            "Epoch 1205/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.8136 - val_loss: 13.6464\n",
            "Epoch 1206/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.1607 - val_loss: 13.7925\n",
            "Epoch 1207/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 16.9408 - val_loss: 14.3721\n",
            "Epoch 1208/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.7418 - val_loss: 17.5291\n",
            "Epoch 1209/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.9747 - val_loss: 16.6802\n",
            "Epoch 1210/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.9314 - val_loss: 13.6346\n",
            "Epoch 1211/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.7769 - val_loss: 17.8517\n",
            "Epoch 1212/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.1576 - val_loss: 16.0119\n",
            "Epoch 1213/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.0341 - val_loss: 15.7275\n",
            "Epoch 1214/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.0682 - val_loss: 14.9461\n",
            "Epoch 1215/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 18.4281 - val_loss: 13.7558\n",
            "Epoch 1216/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 16.5490 - val_loss: 15.8831\n",
            "Epoch 1217/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.1351 - val_loss: 13.6251\n",
            "Epoch 1218/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.1233 - val_loss: 14.5849\n",
            "Epoch 1219/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.7413 - val_loss: 13.8934\n",
            "Epoch 1220/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.8612 - val_loss: 15.9447\n",
            "Epoch 1221/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.9920 - val_loss: 17.7362\n",
            "Epoch 1222/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 17.1805 - val_loss: 14.0684\n",
            "Epoch 1223/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 15.8313 - val_loss: 13.8007\n",
            "Epoch 1224/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.1546 - val_loss: 14.9348\n",
            "Epoch 1225/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.4219 - val_loss: 14.4457\n",
            "Epoch 1226/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.1547 - val_loss: 15.5138\n",
            "Epoch 1227/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.5990 - val_loss: 15.8528\n",
            "Epoch 1228/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 16.6225 - val_loss: 14.3205\n",
            "Epoch 1229/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.0386 - val_loss: 17.5755\n",
            "Epoch 1230/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.8354 - val_loss: 14.4396\n",
            "Epoch 1231/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.1782 - val_loss: 16.5036\n",
            "Epoch 1232/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 16.8732 - val_loss: 15.5226\n",
            "Epoch 1233/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 19.4296 - val_loss: 14.2128\n",
            "Epoch 1234/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.6235 - val_loss: 14.2656\n",
            "Epoch 1235/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.8254 - val_loss: 14.9320\n",
            "Epoch 1236/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.8125 - val_loss: 13.4493\n",
            "Epoch 1237/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.8254 - val_loss: 13.7719\n",
            "Epoch 1238/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.1129 - val_loss: 17.8551\n",
            "Epoch 1239/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.4191 - val_loss: 15.1337\n",
            "Epoch 1240/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.7170 - val_loss: 14.5772\n",
            "Epoch 1241/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.2564 - val_loss: 18.3284\n",
            "Epoch 1242/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.9702 - val_loss: 16.4180\n",
            "Epoch 1243/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.8742 - val_loss: 14.7820\n",
            "Epoch 1244/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.5516 - val_loss: 15.3786\n",
            "Epoch 1245/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.6587 - val_loss: 15.2989\n",
            "Epoch 1246/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 20.0741 - val_loss: 18.3373\n",
            "Epoch 1247/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 21.3515 - val_loss: 13.6624\n",
            "Epoch 1248/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.8877 - val_loss: 14.1631\n",
            "Epoch 1249/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.6633 - val_loss: 14.9840\n",
            "Epoch 1250/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.8210 - val_loss: 15.2052\n",
            "Epoch 1251/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.2256 - val_loss: 21.7709\n",
            "Epoch 1252/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 20.0805 - val_loss: 15.4695\n",
            "Epoch 1253/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 17.0292 - val_loss: 14.0561\n",
            "Epoch 1254/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.9058 - val_loss: 14.6364\n",
            "Epoch 1255/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.6555 - val_loss: 14.7108\n",
            "Epoch 1256/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.0739 - val_loss: 15.7833\n",
            "Epoch 1257/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.8251 - val_loss: 15.4509\n",
            "Epoch 1258/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.3259 - val_loss: 16.0514\n",
            "Epoch 1259/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 19.6451 - val_loss: 14.8740\n",
            "Epoch 1260/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.4797 - val_loss: 13.7379\n",
            "Epoch 1261/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.1676 - val_loss: 14.6324\n",
            "Epoch 1262/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.1688 - val_loss: 14.7549\n",
            "Epoch 1263/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.1659 - val_loss: 13.7886\n",
            "Epoch 1264/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.8211 - val_loss: 14.3547\n",
            "Epoch 1265/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 17.2719 - val_loss: 16.1496\n",
            "Epoch 1266/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.6005 - val_loss: 18.3661\n",
            "Epoch 1267/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 18.4363 - val_loss: 14.9630\n",
            "Epoch 1268/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.2346 - val_loss: 14.1099\n",
            "Epoch 1269/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.8302 - val_loss: 14.8736\n",
            "Epoch 1270/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.9484 - val_loss: 15.0122\n",
            "Epoch 1271/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 20.0876 - val_loss: 14.5487\n",
            "Epoch 1272/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 19.8273 - val_loss: 21.9419\n",
            "Epoch 1273/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 18.7127 - val_loss: 16.4958\n",
            "Epoch 1274/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.7946 - val_loss: 13.6642\n",
            "Epoch 1275/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.8893 - val_loss: 13.3874\n",
            "Epoch 1276/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 15.9456 - val_loss: 14.9801\n",
            "Epoch 1277/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.7786 - val_loss: 16.1766\n",
            "Epoch 1278/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.3867 - val_loss: 16.6149\n",
            "Epoch 1279/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 18.3129 - val_loss: 17.0276\n",
            "Epoch 1280/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.5839 - val_loss: 18.1439\n",
            "Epoch 1281/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 16.7009 - val_loss: 15.1494\n",
            "Epoch 1282/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.6188 - val_loss: 15.4372\n",
            "Epoch 1283/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.6273 - val_loss: 15.9594\n",
            "Epoch 1284/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 16.7660 - val_loss: 13.7294\n",
            "Epoch 1285/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.1524 - val_loss: 15.2237\n",
            "Epoch 1286/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 15.7935 - val_loss: 15.2360\n",
            "Epoch 1287/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.1217 - val_loss: 14.5817\n",
            "Epoch 1288/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 16.1929 - val_loss: 15.1083\n",
            "Epoch 1289/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.8996 - val_loss: 16.2889\n",
            "Epoch 1290/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.1452 - val_loss: 16.0216\n",
            "Epoch 1291/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.7853 - val_loss: 15.9600\n",
            "Epoch 1292/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.0561 - val_loss: 14.3841\n",
            "Epoch 1293/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.7571 - val_loss: 17.1395\n",
            "Epoch 1294/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.0467 - val_loss: 14.7031\n",
            "Epoch 1295/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 15.7919 - val_loss: 14.4628\n",
            "Epoch 1296/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.6933 - val_loss: 13.6286\n",
            "Epoch 1297/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 17.8305 - val_loss: 14.8993\n",
            "Epoch 1298/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.2130 - val_loss: 14.6100\n",
            "Epoch 1299/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.1203 - val_loss: 15.0060\n",
            "Epoch 1300/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 15.4791 - val_loss: 15.3922\n",
            "Epoch 1301/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.5749 - val_loss: 14.3639\n",
            "Epoch 1302/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.9295 - val_loss: 14.3378\n",
            "Epoch 1303/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.4730 - val_loss: 16.2589\n",
            "Epoch 1304/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.1143 - val_loss: 14.5438\n",
            "Epoch 1305/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.4232 - val_loss: 14.9127\n",
            "Epoch 1306/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.4652 - val_loss: 15.1865\n",
            "Epoch 1307/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.7994 - val_loss: 15.1068\n",
            "Epoch 1308/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.6941 - val_loss: 16.1211\n",
            "Epoch 1309/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.9860 - val_loss: 17.4188\n",
            "Epoch 1310/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 16.8545 - val_loss: 15.0423\n",
            "Epoch 1311/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.0740 - val_loss: 15.0261\n",
            "Epoch 1312/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 19.0024 - val_loss: 15.5250\n",
            "Epoch 1313/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 18.4362 - val_loss: 14.3444\n",
            "Epoch 1314/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.3129 - val_loss: 13.7109\n",
            "Epoch 1315/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.4022 - val_loss: 16.5181\n",
            "Epoch 1316/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.3472 - val_loss: 16.6539\n",
            "Epoch 1317/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.0058 - val_loss: 16.4353\n",
            "Epoch 1318/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.7153 - val_loss: 13.6897\n",
            "Epoch 1319/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.6228 - val_loss: 15.2434\n",
            "Epoch 1320/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.6668 - val_loss: 14.9556\n",
            "Epoch 1321/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 15.3142 - val_loss: 14.0950\n",
            "Epoch 1322/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 15.9052 - val_loss: 14.5384\n",
            "Epoch 1323/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.5598 - val_loss: 14.2710\n",
            "Epoch 1324/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.5510 - val_loss: 14.2821\n",
            "Epoch 1325/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.4754 - val_loss: 14.8916\n",
            "Epoch 1326/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.0681 - val_loss: 13.6030\n",
            "Epoch 1327/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 15.9476 - val_loss: 14.2778\n",
            "Epoch 1328/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.5104 - val_loss: 16.5643\n",
            "Epoch 1329/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.3130 - val_loss: 13.6916\n",
            "Epoch 1330/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.5079 - val_loss: 13.9724\n",
            "Epoch 1331/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.0969 - val_loss: 14.1337\n",
            "Epoch 1332/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.0387 - val_loss: 15.4949\n",
            "Epoch 1333/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 15.7699 - val_loss: 14.5338\n",
            "Epoch 1334/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 15.9623 - val_loss: 16.8091\n",
            "Epoch 1335/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 17.6710 - val_loss: 14.0427\n",
            "Epoch 1336/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 15.9706 - val_loss: 13.7120\n",
            "Epoch 1337/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.1523 - val_loss: 14.6909\n",
            "Epoch 1338/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.6996 - val_loss: 13.9801\n",
            "Epoch 1339/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.0369 - val_loss: 16.2220\n",
            "Epoch 1340/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.7447 - val_loss: 14.4533\n",
            "Epoch 1341/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.2838 - val_loss: 13.9947\n",
            "Epoch 1342/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.4935 - val_loss: 13.7654\n",
            "Epoch 1343/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.4514 - val_loss: 16.8325\n",
            "Epoch 1344/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.3019 - val_loss: 15.3149\n",
            "Epoch 1345/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.3304 - val_loss: 14.1529\n",
            "Epoch 1346/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.9714 - val_loss: 14.6720\n",
            "Epoch 1347/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 15.9683 - val_loss: 15.5436\n",
            "Epoch 1348/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.5432 - val_loss: 14.8036\n",
            "Epoch 1349/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.4240 - val_loss: 16.7018\n",
            "Epoch 1350/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.5067 - val_loss: 16.5246\n",
            "Epoch 1351/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 16.0978 - val_loss: 13.8272\n",
            "Epoch 1352/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.4991 - val_loss: 14.8693\n",
            "Epoch 1353/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.0762 - val_loss: 15.0048\n",
            "Epoch 1354/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 16.3800 - val_loss: 13.4756\n",
            "Epoch 1355/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 15.3887 - val_loss: 14.8544\n",
            "Epoch 1356/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.4148 - val_loss: 14.5034\n",
            "Epoch 1357/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.7712 - val_loss: 14.1646\n",
            "Epoch 1358/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 15.8195 - val_loss: 13.5615\n",
            "Epoch 1359/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.0788 - val_loss: 15.2519\n",
            "Epoch 1360/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.3904 - val_loss: 14.3141\n",
            "Epoch 1361/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 15.8652 - val_loss: 14.4833\n",
            "Epoch 1362/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.3181 - val_loss: 15.8880\n",
            "Epoch 1363/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 15.8905 - val_loss: 16.2716\n",
            "Epoch 1364/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.3938 - val_loss: 15.4055\n",
            "Epoch 1365/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.1218 - val_loss: 17.2401\n",
            "Epoch 1366/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.4405 - val_loss: 17.3140\n",
            "Epoch 1367/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 15.7676 - val_loss: 13.5865\n",
            "Epoch 1368/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.1547 - val_loss: 14.2012\n",
            "Epoch 1369/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.0363 - val_loss: 17.7349\n",
            "Epoch 1370/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.4008 - val_loss: 15.6780\n",
            "Epoch 1371/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.0392 - val_loss: 14.7308\n",
            "Epoch 1372/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.9056 - val_loss: 14.7993\n",
            "Epoch 1373/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.4218 - val_loss: 19.7450\n",
            "Epoch 1374/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.4390 - val_loss: 16.5413\n",
            "Epoch 1375/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 20.6175 - val_loss: 16.1734\n",
            "Epoch 1376/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.1031 - val_loss: 14.6657\n",
            "Epoch 1377/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 15.5883 - val_loss: 14.1936\n",
            "Epoch 1378/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 15.4707 - val_loss: 13.6806\n",
            "Epoch 1379/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.9769 - val_loss: 14.3393\n",
            "Epoch 1380/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 15.4052 - val_loss: 14.2955\n",
            "Epoch 1381/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 14.7399 - val_loss: 14.4819\n",
            "Epoch 1382/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 17.7134 - val_loss: 15.6616\n",
            "Epoch 1383/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.3888 - val_loss: 15.7965\n",
            "Epoch 1384/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.6733 - val_loss: 16.5277\n",
            "Epoch 1385/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.5586 - val_loss: 21.5191\n",
            "Epoch 1386/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.7777 - val_loss: 15.8879\n",
            "Epoch 1387/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 15.1925 - val_loss: 15.1715\n",
            "Epoch 1388/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.1391 - val_loss: 19.1320\n",
            "Epoch 1389/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.2976 - val_loss: 14.2571\n",
            "Epoch 1390/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.6654 - val_loss: 13.5484\n",
            "Epoch 1391/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.0506 - val_loss: 14.7708\n",
            "Epoch 1392/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 16.5042 - val_loss: 21.6283\n",
            "Epoch 1393/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.1514 - val_loss: 18.7143\n",
            "Epoch 1394/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.0168 - val_loss: 14.4737\n",
            "Epoch 1395/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.2580 - val_loss: 15.5633\n",
            "Epoch 1396/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 14.9403 - val_loss: 15.5073\n",
            "Epoch 1397/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.9517 - val_loss: 14.6336\n",
            "Epoch 1398/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.7884 - val_loss: 14.6789\n",
            "Epoch 1399/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.2337 - val_loss: 14.4558\n",
            "Epoch 1400/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.8250 - val_loss: 14.1224\n",
            "Epoch 1401/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 15.1529 - val_loss: 15.2236\n",
            "Epoch 1402/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.1766 - val_loss: 14.3250\n",
            "Epoch 1403/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.0830 - val_loss: 15.5080\n",
            "Epoch 1404/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.1840 - val_loss: 14.4529\n",
            "Epoch 1405/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.8914 - val_loss: 16.0880\n",
            "Epoch 1406/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 15.4972 - val_loss: 14.3054\n",
            "Epoch 1407/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.9344 - val_loss: 14.4138\n",
            "Epoch 1408/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.1792 - val_loss: 14.2005\n",
            "Epoch 1409/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.6105 - val_loss: 14.0583\n",
            "Epoch 1410/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.1058 - val_loss: 18.8521\n",
            "Epoch 1411/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 16.1839 - val_loss: 13.5653\n",
            "Epoch 1412/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.0209 - val_loss: 14.1745\n",
            "Epoch 1413/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 15.7112 - val_loss: 13.9483\n",
            "Epoch 1414/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.4833 - val_loss: 13.7653\n",
            "Epoch 1415/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.1719 - val_loss: 15.2842\n",
            "Epoch 1416/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.1446 - val_loss: 13.9410\n",
            "Epoch 1417/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 15.1245 - val_loss: 13.9655\n",
            "Epoch 1418/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.6942 - val_loss: 13.9596\n",
            "Epoch 1419/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 16.9957 - val_loss: 14.9809\n",
            "Epoch 1420/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.8796 - val_loss: 17.8718\n",
            "Epoch 1421/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.9033 - val_loss: 14.1697\n",
            "Epoch 1422/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.5300 - val_loss: 14.1228\n",
            "Epoch 1423/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 15.9117 - val_loss: 15.6135\n",
            "Epoch 1424/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.4889 - val_loss: 17.3883\n",
            "Epoch 1425/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.3031 - val_loss: 23.0450\n",
            "Epoch 1426/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 18.3617 - val_loss: 15.3205\n",
            "Epoch 1427/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 15.0089 - val_loss: 16.4337\n",
            "Epoch 1428/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.1591 - val_loss: 15.2960\n",
            "Epoch 1429/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.6760 - val_loss: 16.7440\n",
            "Epoch 1430/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.4137 - val_loss: 14.0131\n",
            "Epoch 1431/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.5003 - val_loss: 14.5498\n",
            "Epoch 1432/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.6954 - val_loss: 14.0203\n",
            "Epoch 1433/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.8042 - val_loss: 14.1876\n",
            "Epoch 1434/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 14.5697 - val_loss: 13.7890\n",
            "Epoch 1435/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.3530 - val_loss: 14.9688\n",
            "Epoch 1436/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.8093 - val_loss: 15.6804\n",
            "Epoch 1437/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 16.1456 - val_loss: 16.8510\n",
            "Epoch 1438/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.9924 - val_loss: 14.8263\n",
            "Epoch 1439/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 14.7273 - val_loss: 16.9007\n",
            "Epoch 1440/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.8476 - val_loss: 13.8497\n",
            "Epoch 1441/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.9140 - val_loss: 14.9272\n",
            "Epoch 1442/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.3285 - val_loss: 14.8621\n",
            "Epoch 1443/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.7224 - val_loss: 16.3043\n",
            "Epoch 1444/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 16.1066 - val_loss: 15.3778\n",
            "Epoch 1445/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 17.5427 - val_loss: 15.4699\n",
            "Epoch 1446/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.5931 - val_loss: 13.9492\n",
            "Epoch 1447/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.2491 - val_loss: 15.0754\n",
            "Epoch 1448/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 15.7495 - val_loss: 14.7627\n",
            "Epoch 1449/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.9117 - val_loss: 14.1513\n",
            "Epoch 1450/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.3398 - val_loss: 15.3245\n",
            "Epoch 1451/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 15.1970 - val_loss: 14.3724\n",
            "Epoch 1452/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.2890 - val_loss: 14.1638\n",
            "Epoch 1453/1500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 15.1869 - val_loss: 15.7656\n",
            "Epoch 1454/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.8553 - val_loss: 15.8609\n",
            "Epoch 1455/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.7864 - val_loss: 17.7793\n",
            "Epoch 1456/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.5503 - val_loss: 16.7937\n",
            "Epoch 1457/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 16.5421 - val_loss: 14.3410\n",
            "Epoch 1458/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.0297 - val_loss: 15.2814\n",
            "Epoch 1459/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.3196 - val_loss: 14.6190\n",
            "Epoch 1460/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 15.3685 - val_loss: 15.8421\n",
            "Epoch 1461/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.4941 - val_loss: 16.1707\n",
            "Epoch 1462/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.4400 - val_loss: 13.7854\n",
            "Epoch 1463/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 15.0561 - val_loss: 14.3385\n",
            "Epoch 1464/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.9366 - val_loss: 17.3029\n",
            "Epoch 1465/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 14.8141 - val_loss: 13.6257\n",
            "Epoch 1466/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.2169 - val_loss: 15.4228\n",
            "Epoch 1467/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 19.1675 - val_loss: 17.9653\n",
            "Epoch 1468/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 18.2760 - val_loss: 15.1225\n",
            "Epoch 1469/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 16.0279 - val_loss: 14.6870\n",
            "Epoch 1470/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.3519 - val_loss: 15.1942\n",
            "Epoch 1471/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.9370 - val_loss: 14.7297\n",
            "Epoch 1472/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.7884 - val_loss: 13.7070\n",
            "Epoch 1473/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 14.3120 - val_loss: 13.9911\n",
            "Epoch 1474/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.8549 - val_loss: 15.9082\n",
            "Epoch 1475/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.5568 - val_loss: 13.9427\n",
            "Epoch 1476/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.9769 - val_loss: 13.9814\n",
            "Epoch 1477/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.1499 - val_loss: 14.4409\n",
            "Epoch 1478/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.7780 - val_loss: 13.8529\n",
            "Epoch 1479/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 14.6624 - val_loss: 13.6562\n",
            "Epoch 1480/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 15.3956 - val_loss: 14.0128\n",
            "Epoch 1481/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 15.1654 - val_loss: 14.7797\n",
            "Epoch 1482/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.8008 - val_loss: 14.6099\n",
            "Epoch 1483/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 15.8013 - val_loss: 15.6290\n",
            "Epoch 1484/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.0777 - val_loss: 14.8636\n",
            "Epoch 1485/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 19.8938 - val_loss: 19.2645\n",
            "Epoch 1486/1500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 18.7753 - val_loss: 15.9606\n",
            "Epoch 1487/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.2583 - val_loss: 17.4755\n",
            "Epoch 1488/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.7008 - val_loss: 15.0453\n",
            "Epoch 1489/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 15.6899 - val_loss: 15.3383\n",
            "Epoch 1490/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.8553 - val_loss: 14.1315\n",
            "Epoch 1491/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 14.6046 - val_loss: 14.0159\n",
            "Epoch 1492/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.6239 - val_loss: 14.5719\n",
            "Epoch 1493/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 14.8008 - val_loss: 16.9407\n",
            "Epoch 1494/1500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 15.2304 - val_loss: 14.7181\n",
            "Epoch 1495/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.4548 - val_loss: 14.2745\n",
            "Epoch 1496/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.7159 - val_loss: 15.3989\n",
            "Epoch 1497/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 14.9526 - val_loss: 14.1974\n",
            "Epoch 1498/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.6691 - val_loss: 15.0067\n",
            "Epoch 1499/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 16.3528 - val_loss: 14.4889\n",
            "Epoch 1500/1500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 15.9181 - val_loss: 13.6622\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoQRtz1x5snf"
      },
      "source": [
        "model.save('/content/20858688_RNN_model.h5')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kObhZZ1PWIIb"
      },
      "source": [
        "def plot_acc_loss(hist):\n",
        "  loss = hist.history['loss']\n",
        "  val_loss = hist.history['val_loss']\n",
        "  epochs = range(len(loss))\n",
        "\n",
        "  plt.plot(epochs, loss, 'g', label='Training loss')\n",
        "  plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df5aSyNJWO_E",
        "outputId": "3ad6cc48-aad3-4981-d179-ade903be8709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot_acc_loss(lstm_out)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBiBHq9YZFqE"
      },
      "source": [
        "y_test=np.array(y_test)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZU3QUcfY54f"
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYEO1HLdZbtv"
      },
      "source": [
        "result_array=pd.DataFrame({'y_test':y_test, 'y_predicted':y_pred.ravel(),'Date':X_test_date[\"Date\"]},index=None)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1t5KMaW3cW3",
        "outputId": "16915105-1a94-43fb-954b-8d64d5048e61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "result_array=result_array.reset_index(drop=True, inplace=False)\n",
        "result_array"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_test</th>\n",
              "      <th>y_predicted</th>\n",
              "      <th>Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.85</td>\n",
              "      <td>123.682236</td>\n",
              "      <td>2015-07-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.72</td>\n",
              "      <td>128.437057</td>\n",
              "      <td>2015-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>129.08</td>\n",
              "      <td>130.907776</td>\n",
              "      <td>2015-07-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>130.97</td>\n",
              "      <td>129.237274</td>\n",
              "      <td>2015-07-20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>132.85</td>\n",
              "      <td>125.027435</td>\n",
              "      <td>2015-07-21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372</th>\n",
              "      <td>318.66</td>\n",
              "      <td>315.629517</td>\n",
              "      <td>2020-05-21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>317.75</td>\n",
              "      <td>318.411926</td>\n",
              "      <td>2020-06-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>351.41</td>\n",
              "      <td>349.774261</td>\n",
              "      <td>2020-06-18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375</th>\n",
              "      <td>360.70</td>\n",
              "      <td>359.228638</td>\n",
              "      <td>2020-06-25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>353.25</td>\n",
              "      <td>358.746002</td>\n",
              "      <td>2020-06-29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>377 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     y_test  y_predicted       Date\n",
              "0    123.85   123.682236 2015-07-09\n",
              "1    125.72   128.437057 2015-07-15\n",
              "2    129.08   130.907776 2015-07-17\n",
              "3    130.97   129.237274 2015-07-20\n",
              "4    132.85   125.027435 2015-07-21\n",
              "..      ...          ...        ...\n",
              "372  318.66   315.629517 2020-05-21\n",
              "373  317.75   318.411926 2020-06-01\n",
              "374  351.41   349.774261 2020-06-18\n",
              "375  360.70   359.228638 2020-06-25\n",
              "376  353.25   358.746002 2020-06-29\n",
              "\n",
              "[377 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyc4Q3zraUGj",
        "outputId": "0dfcee33-88bd-4cbd-9d99-fa9167e6fcd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        }
      },
      "source": [
        "result_array.iloc[0:,0:2].plot.line(figsize=(13,8))\n",
        "plt.xticks(np.arange(0, 377, step=20), result_array[\"Date\"].dt.date.iloc[lambda x: x.index % 20 == 0],rotation=45)\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Opening price')\n",
        "plt.title('Comparioson')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Comparioson')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 936x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}